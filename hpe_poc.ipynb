{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf70416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e56c7d",
   "metadata": {},
   "source": [
    "## YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.common.mutators import convert_to_bgr\n",
    "from src.hpe.yolo.performance import DistanceCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default estimation\n",
    "collector = DistanceCollector()\n",
    "distances = collector.collect(name=\"distances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation on bgr images\n",
    "distances_bgr = collector.collect(\n",
    "    name=\"distances_bgr\",\n",
    "    image_mutators=[convert_to_bgr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fa9335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels\n"
     ]
    }
   ],
   "source": [
    "from src.hpe.yolo.performance import PerformanceLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bc66e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 39.2ms\n",
      "Speed: 29.1ms preprocess, 39.2ms inference, 928.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 41.1ms\n",
      "Speed: 4.2ms preprocess, 41.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 2 persons, 16.9ms\n",
      "Speed: 3.4ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 (no detections), 17.0ms\n",
      "Speed: 2.7ms preprocess, 17.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 person, 15.9ms\n",
      "Speed: 2.6ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 16.6ms\n",
      "Speed: 2.9ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 person, 16.0ms\n",
      "Speed: 2.6ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 17.4ms\n",
      "Speed: 2.7ms preprocess, 17.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 15.7ms\n",
      "Speed: 2.8ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 person, 15.7ms\n",
      "Speed: 2.7ms preprocess, 15.7ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 16.2ms\n",
      "Speed: 2.7ms preprocess, 16.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 2 persons, 15.4ms\n",
      "Speed: 2.9ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 2 persons, 15.7ms\n",
      "Speed: 2.6ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 2 persons, 16.0ms\n",
      "Speed: 2.7ms preprocess, 16.0ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 17.0ms\n",
      "Speed: 2.8ms preprocess, 17.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 person, 15.6ms\n",
      "Speed: 2.5ms preprocess, 15.6ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 16.7ms\n",
      "Speed: 2.6ms preprocess, 16.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 2 persons, 14.9ms\n",
      "Speed: 2.9ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 15.4ms\n",
      "Speed: 2.9ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 person, 15.4ms\n",
      "Speed: 2.5ms preprocess, 15.4ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 17.4ms\n",
      "Speed: 4.1ms preprocess, 17.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 person, 15.2ms\n",
      "Speed: 2.9ms preprocess, 15.2ms inference, 2.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 15.5ms\n",
      "Speed: 2.9ms preprocess, 15.5ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 15.3ms\n",
      "Speed: 3.0ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 2 persons, 16.0ms\n",
      "Speed: 3.0ms preprocess, 16.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 17.2ms\n",
      "Speed: 3.0ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 15.3ms\n",
      "Speed: 2.8ms preprocess, 15.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 2 persons, 15.7ms\n",
      "Speed: 2.9ms preprocess, 15.7ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 15.6ms\n",
      "Speed: 2.9ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 16.0ms\n",
      "Speed: 2.9ms preprocess, 16.0ms inference, 3.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 15.7ms\n",
      "Speed: 2.8ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 19.4ms\n",
      "Speed: 3.1ms preprocess, 19.4ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 16.1ms\n",
      "Speed: 2.8ms preprocess, 16.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 640x448 1 person, 15.3ms\n",
      "Speed: 2.8ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "0: 448x640 1 person, 15.8ms\n",
      "Speed: 2.8ms preprocess, 15.8ms inference, 3.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 14.7ms\n",
      "Speed: 2.4ms preprocess, 14.7ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x448 1 person, 16.1ms\n",
      "Speed: 3.1ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 448)\n",
      "Percentage of landmarks detected correctly: 0.356120826709062%\n",
      "Yolov11m-pose can only detect 17 landmarks of our 32 labels\n"
     ]
    }
   ],
   "source": [
    "logger = PerformanceLogger()\n",
    "logger.collect(name=\"Yolov11m-pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79334659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and log performance on bgr images\n",
    "logger.collect(\n",
    "    name=\"Yolov11m-pose on bgr\",\n",
    "    image_mutators=[convert_to_bgr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817fcb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.yolo.performance import read_distances\n",
    "\n",
    "distances = read_distances()\n",
    "distances_bgr = read_distances(dataset_name=\"distances_bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c494644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.yolo.plot import plot_yolo_average_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_yolo_average_distances(distances=distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7090a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_yolo_average_distances(distances=distances_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58717d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.yolo.play import play_with_hpe as play_with_yolo_hpe\n",
    "from glob import glob\n",
    "from random import choice\n",
    "\n",
    "video_paths = glob(\"data/samples/**/*.*\")\n",
    "video_path = choice(video_paths)\n",
    "\n",
    "play_with_yolo_hpe(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a78070",
   "metadata": {},
   "source": [
    "## MediaPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ab545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.mp.performance import DistanceCollector\n",
    "from src.hpe.common.mutators import convert_to_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e195c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = DistanceCollector()\n",
    "distances = collector.collect(name=\"distances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation on bgr images\n",
    "distances_bgr = collector.collect(\n",
    "    name=\"distances_bgr\",\n",
    "    image_mutators=[convert_to_bgr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.mp.performance import PerformanceLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad50d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = PerformanceLogger()\n",
    "logger.collect(name=\"MediaPipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860926b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.collect(name=\"MediaPipe on bgr\",\n",
    "    image_mutators=[convert_to_bgr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2942be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.mp.performance import read_distances\n",
    "distances = read_distances()\n",
    "distances_bgr = read_distances(dataset_name=\"distances_bgr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e2b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.mp.plot import plot_mediapipe_average_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_mediapipe_average_distances(distances=distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5768ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mediapipe_average_distances(distances=distances_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.mp.play import play_with_hpe\n",
    "from glob import glob\n",
    "from random import choice\n",
    "\n",
    "video_paths = glob(\"data/samples/**/*.*\")\n",
    "video_path = choice(video_paths)\n",
    "\n",
    "play_with_hpe(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c673b2f",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb78b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.yolo.performance import read_distances as read_yolo_distances\n",
    "from src.hpe.mp.performance import read_distances as read_mp_distances\n",
    "from src.hpe.common.plot import plot_distances_boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_dist = read_mp_distances(dataset_name=\"distances\")\n",
    "mp_bgr_dist = read_mp_distances(dataset_name=\"distances_bgr\")\n",
    "\n",
    "yolo_dist = read_yolo_distances(dataset_name=\"distances\")\n",
    "yolo_bgr_dist = read_yolo_distances(dataset_name=\"distances_bgr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8587fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distances_boxplot(\n",
    "    None,\n",
    "    (\"MediaPipe\", mp_dist),\n",
    "    (\"MediaPipe on bgr\", mp_bgr_dist),\n",
    "    (\"Yolov11\", yolo_dist),\n",
    "    (\"Yolov11 on bgr\", yolo_bgr_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distances_boxplot(\n",
    "    (0, 10),\n",
    "    (\"MediaPipe\", mp_dist),\n",
    "    (\"MediaPipe on bgr\", mp_bgr_dist),\n",
    "    (\"Yolov11\", yolo_dist),\n",
    "    (\"Yolov11 on bgr\", yolo_bgr_dist))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
