{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.sampling.images import plot_frame_count_distributions\n",
        "\n",
        "samples_root_dir = \"data/samples\"\n",
        "\n",
        "plot_frame_count_distributions(samples_root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.kfold import HpeDnnFoldCrossValidation\n",
        "from src.sota.kfold import SOTAFoldCrossValidation\n",
        "from src.common.plot import box_plot_accuracies\n",
        "\n",
        "box_plot_accuracies(\n",
        "    HpeDnnFoldCrossValidation.evaluation_instance(\"arch1-kf\"),\n",
        "    HpeDnnFoldCrossValidation.evaluation_instance(\"arch2-kf\"), \n",
        "    HpeDnnFoldCrossValidation.evaluation_instance(\"arch3-kf\"), \n",
        "    HpeDnnFoldCrossValidation.evaluation_instance(\"arch4-kf\"), \n",
        "    HpeDnnFoldCrossValidation.evaluation_instance(\"arch5-kf\"),\n",
        "    SOTAFoldCrossValidation.evaluation_instance(\"yolo11n-kf\", \"yolov11n-cls\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe.mp.landmarks import get_feature_labels as get_mp_feature_labels\n",
        "\n",
        "mp_features = get_mp_feature_labels()\n",
        "print(mp_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import array, concatenate\n",
        "from typing import List\n",
        "\n",
        "from src.hpe.common.labels import MyLandmark\n",
        "\n",
        "def get_name(landmark: MyLandmark):\n",
        "    return landmark.name\n",
        "\n",
        "def to_features(name: str) -> List[str]:\n",
        "    return [name+\"_x\", name+\"_y\", name+\"_z\", name+\"_visibility\"]\n",
        "\n",
        "def get_feature_labels():\n",
        "    names = list(map(get_name, MyLandmark))\n",
        "    features = concatenate(list(map(to_features, names)))\n",
        "    return array(features)\n",
        "\n",
        "features = get_feature_labels()\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(mp_features == features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Any, List, Callable\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.engine.results import Results\n",
        "from numpy import ndarray\n",
        "\n",
        "from src.labels import get_label_value_from_path\n",
        "from src.hpe.yolo.model import build_pose_model\n",
        "from src.hpe.yolo.evaluate import predict_landmarks\n",
        "\n",
        "def __to_np_array(results: Results) -> ndarray:\n",
        "    pass\n",
        "\n",
        "def to_feature_vector(image_path: str, model: YOLO) -> ndarray:\n",
        "    _, results, _ = predict_landmarks(image_path, model)\n",
        "\n",
        "    pass\n",
        "\n",
        "def evaluate_images(image_paths: List[str]) -> List[List[Any]]:\n",
        "    model = build_pose_model()\n",
        "    \n",
        "    def image_2_features(image_path: str) -> List[Any]:\n",
        "        label = get_label_value_from_path(image_path)\n",
        "        features = to_feature_vector(image_path, model)\n",
        "        return [*features, label, image_path]\n",
        "    \n",
        "    return list(map(image_2_features, image_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from src.hpe.yolo.evaluate import predict_landmarks\n",
        "\n",
        "_, results, _ = predict_landmarks(\"data/img/techniques/train/BACK_FLAG/(Climbing Analysis) Inside Flag - The Move You Never Do But Maybe Should__22__31.png\", YOLO(\"yolo11x-pose.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results.keypoints.data[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas import DataFrame, concat\n",
        "from os.path import join, isdir, exists\n",
        "from os import listdir, makedirs, mkdir\n",
        "from numpy import zeros\n",
        "from glob import glob\n",
        "from typing import Any, List, Callable\n",
        "\n",
        "from src.common.helpers import imread\n",
        "from src.labels import get_label_value_from_path\n",
        "from src.common.helpers import read_dataframe\n",
        "from src.hpe.mp.model import build_holistic_model\n",
        "from src.hpe.mp.evaluate import to_feature_vector\n",
        "from src.hpe.mp.landmarks import get_feature_labels\n",
        "\n",
        "def generate_hpe_feature_df(data_path,\n",
        "        evaluate_func: Callable[[List[str]], List[List[Any]]],\n",
        "        img_dataset_name = \"techniques\",\n",
        "        df_dataset_name = \"techniques\"):\n",
        "\n",
        "    feature_names = get_feature_labels()\n",
        "    column_names = [*feature_names, \"technique\", \"image_path\"]\n",
        "    \n",
        "    img_path = join(data_path, \"img\", img_dataset_name)\n",
        "    df_path = join(data_path, \"df\", df_dataset_name)\n",
        "    if (not exists(df_path)):\n",
        "        makedirs(df_path)\n",
        "\n",
        "    for data_split in listdir(img_path):\n",
        "        data_split_path = join(img_path, data_split)\n",
        "        if (isdir(data_split_path)):\n",
        "            image_paths = glob(data_split_path + \"/**/*.*\", recursive=True)\n",
        "            matrix = evaluate_func(image_paths)        \n",
        "            df = DataFrame(data=matrix, columns=column_names)\n",
        "            df.to_pickle(join(df_path, f\"{data_split}.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_hpe_feature_df(data_path=\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.common.helpers import read_dataframe\n",
        "\n",
        "df = read_dataframe(\"data/df/techniques/test.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sota K-Fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from src.sota.model import SOTAConstructorArgs, SOTAMultiRunTrainArgs, SOTATrainArgs\n",
        "from src.sota.kfold import SOTAFoldCrossValidation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_validation = SOTAFoldCrossValidation(\n",
        "    model_args = SOTAConstructorArgs(name=\"yolo11n-kf\", model_arch=\"yolo11n-cls\"),\n",
        "    train_run_args = SOTAMultiRunTrainArgs(\n",
        "        runs=2,\n",
        "        train_args=SOTATrainArgs(epochs=10, balanced=True)\n",
        "    )\n",
        ")\n",
        "\n",
        "cross_validation.test_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# yolo11m unbalanced\n",
        "cross_validation = SOTAFoldCrossValidation(\n",
        "    model_args = SOTAConstructorArgs(name=\"yolo11m-unbalanced-kf\", model_arch=\"yolo11m-cls\"),\n",
        "    train_run_args = SOTAMultiRunTrainArgs(\n",
        "        runs=1,\n",
        "        train_args=SOTATrainArgs(epochs=10, balanced=False)\n",
        "    )\n",
        ")\n",
        "\n",
        "cross_validation.train_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# yolo11n unbalanced\n",
        "cross_validation = SOTAFoldCrossValidation(\n",
        "    model_args = SOTAConstructorArgs(name=\"yolo11n-unbalanced-kf\", model_arch=\"yolo11n-cls\"),\n",
        "    train_run_args = SOTAMultiRunTrainArgs(\n",
        "        runs=1,\n",
        "        train_args=SOTATrainArgs(epochs=10, balanced=False)\n",
        "    )\n",
        ")\n",
        "\n",
        "cross_validation.train_folds()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HPE DNN K-Fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from src.hpe_dnn.architecture import DnnArch\n",
        "from src.hpe_dnn.model import HpeDnnModelInitializeArgs, HpeDnnMultiRunTrainArgs, HpeDnnTrainArgs, HpeDnnConstructorArgs\n",
        "from src.hpe_dnn.kfold import HpeDnnFoldCrossValidation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_validation = HpeDnnFoldCrossValidation(\n",
        "    model_args=HpeDnnConstructorArgs(name=\"arch1-kf\", model_arch=DnnArch.ARCH1),\n",
        "    train_run_args=HpeDnnMultiRunTrainArgs(\n",
        "        runs=2,\n",
        "        train_args=HpeDnnTrainArgs(epochs=10, balanced=True, augment=True)\n",
        "    ))\n",
        "\n",
        "cross_validation.test_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_validation = HpeDnnFoldCrossValidation(\n",
        "    model_args=HpeDnnConstructorArgs(name=\"arch1-dr0.3-kf\", model_arch=DnnArch.ARCH1),\n",
        "    train_run_args=HpeDnnMultiRunTrainArgs(\n",
        "        runs=2,\n",
        "        model_initialize_args=HpeDnnModelInitializeArgs(dropout_rate=0.3),\n",
        "        train_args=HpeDnnTrainArgs(epochs=10, balanced=True, augment=True)\n",
        "    ))\n",
        "\n",
        "cross_validation.test_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# arch1 unbalanced\n",
        "cross_validation = HpeDnnFoldCrossValidation(\n",
        "    model_args=HpeDnnConstructorArgs(name=\"arch1-unbalanced-kf\", model_arch=DnnArch.ARCH1),\n",
        "    train_run_args=HpeDnnMultiRunTrainArgs(\n",
        "        runs=5,\n",
        "        train_args=HpeDnnTrainArgs(epochs=10, balanced=False, augment=True)\n",
        "    ))\n",
        "\n",
        "cross_validation.test_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# arch1 unaugmented\n",
        "cross_validation = HpeDnnFoldCrossValidation(\n",
        "    model_args=HpeDnnConstructorArgs(name=\"arch1-unaugmented-kf\", model_arch=DnnArch.ARCH1),\n",
        "    train_run_args=HpeDnnMultiRunTrainArgs(\n",
        "        runs=5,\n",
        "        train_args=HpeDnnTrainArgs(epochs=10, balanced=False, augment=False)\n",
        "    ))\n",
        "\n",
        "cross_validation.train_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_validation = HpeDnnFoldCrossValidation(\n",
        "    model_args=HpeDnnConstructorArgs(name=\"arch2-kf\", model_arch=DnnArch.ARCH2),\n",
        "    train_run_args=HpeDnnMultiRunTrainArgs(\n",
        "        runs=1,\n",
        "        train_args=HpeDnnTrainArgs(epochs=10, balanced=True, augment=True)\n",
        "    ))\n",
        "\n",
        "cross_validation.test_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_validation = HpeDnnFoldCrossValidation(\n",
        "    model_args=HpeDnnConstructorArgs(name=\"arch3-kf\", model_arch=DnnArch.ARCH3),\n",
        "    train_run_args=HpeDnnMultiRunTrainArgs(\n",
        "        runs=1,\n",
        "        train_args=HpeDnnTrainArgs(epochs=10, balanced=True, augment=True)\n",
        "    ))\n",
        "\n",
        "cross_validation.test_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_validation = HpeDnnFoldCrossValidation(\n",
        "    model_args=HpeDnnConstructorArgs(name=\"arch4-kf\", model_arch=DnnArch.ARCH4),\n",
        "    train_run_args=HpeDnnMultiRunTrainArgs(\n",
        "        runs=1,\n",
        "        train_args=HpeDnnTrainArgs(epochs=10, balanced=True, augment=True)\n",
        "    ))\n",
        "\n",
        "cross_validation.test_folds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_validation = HpeDnnFoldCrossValidation(\n",
        "    model_args=HpeDnnConstructorArgs(name=\"arch5-kf\", model_arch=DnnArch.ARCH5),\n",
        "    train_run_args=HpeDnnMultiRunTrainArgs(\n",
        "        runs=2,\n",
        "        train_args=HpeDnnTrainArgs(epochs=10, balanced=True, augment=True)\n",
        "    ))\n",
        "\n",
        "cross_validation.test_folds()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sota model training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.common.model import ModelInitializeArgs, TestArgs\n",
        "from src.sota.model import SOTA, SOTAConstructorArgs\n",
        "\n",
        "sota = SOTA(args=SOTAConstructorArgs(\"yolo11m-cls\"))\n",
        "sota.initialize_model(args=ModelInitializeArgs())\n",
        "\n",
        "#sota.execute_train_runs(model=\"yolo11m-cls\", runs=3, epochs=10, balanced=False)\n",
        "sota.test_model(args=TestArgs(write_to_wandb=False))\n",
        "\n",
        "#sota.train_model(optimizer=\"AdamW\", lr0=0.0005)\n",
        "\n",
        "#metrics = model.val(data=\"data/img/techniques/val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.sota.model import SOTA\n",
        "\n",
        "sota = SOTA(\"data\", \"yolo11n-cls\")\n",
        "sota.execute_train_runs(model=\"yolo11n-cls\", runs=5, epochs=10, balanced=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.sota.model import SOTA\n",
        "\n",
        "sota = SOTA(\"data\", \"yolo11m-cls-balanced\")\n",
        "sota.execute_train_runs(model=\"yolo11m-cls\", runs=5, epochs=10, balanced=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.sota.model import SOTA\n",
        "\n",
        "sota = SOTA(\"data\", \"yolo11n-cls-full-balanced\")\n",
        "sota.execute_train_runs(model=\"yolo11n-cls\", runs=2, epochs=5, balanced=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.sota.model import SOTA\n",
        "\n",
        "sota = SOTA(\"data\", \"yolo11m-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
        "sota.initialize_model(\"yolo11m-cls\")\n",
        "sota.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.sota.model import SOTA\n",
        "\n",
        "sota = SOTA(\"data\", \"yolo11n-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
        "sota.initialize_model(\"yolo11n-cls\")\n",
        "#sota.train_model()\n",
        "sota.test_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sota model testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.sota.model import SOTA\n",
        "\n",
        "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
        "metrics = sota.test_model(write_to_wandb=False)\n",
        "\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics.top1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HPE DNN model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.architecture import DnnArch\n",
        "from src.common.model import TestArgs\n",
        "from src.hpe_dnn.model import HpeDnn, HpeDnnConstructorArgs, HpeDnnModelInitializeArgs, HpeDnnTrainArgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Unity model for testing\n",
        "hpednn = HpeDnn(args=HpeDnnConstructorArgs(name=\"unity\", model_arch=DnnArch.ARCH1, dataset_name=\"unity\"))\n",
        "hpednn.initialize_model(args=HpeDnnModelInitializeArgs())\n",
        "hpednn.train_model(args=HpeDnnTrainArgs(epochs=10))\n",
        "hpednn.test_model(args=TestArgs())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hpednn = HpeDnn(args=HpeDnnConstructorArgs(name=\"arch1-kf-fold1\", model_arch=DnnArch.ARCH1))\n",
        "hpednn.initialize_model(args=HpeDnnModelInitializeArgs())\n",
        "\n",
        "hpednn.model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hpednn = HpeDnn(args=HpeDnnConstructorArgs(name=\"arch1\", model_arch=DnnArch.ARCH1))\n",
        "hpednn.initialize_model(args=HpeDnnModelInitializeArgs())\n",
        "\n",
        "hpednn.model.summary()\n",
        "#hpednn.train_model(args=HpeDnnTrainArgs(epochs=10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hpednn = HpeDnn(\"data\", \"arch1-balanced\")\n",
        "hpednn.execute_train_runs(runs=5, epochs=10, augment=True, balanced=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "from src.hpe_dnn.model import HpeDnn\n",
        "\n",
        "hpednn = HpeDnn(\"data\", \"arch1_balanced\", \"techniques_balanced\")\n",
        "hpednn.initialize_model()\n",
        "hpednn.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from os.path import join\n",
        "run_dir = join(\"data\", \"sota\", \"yolo11n-cls-full-balanced\")\n",
        "run_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.model import HpeDnn\n",
        "\n",
        "hpednn = HpeDnn(\"data\", \"arch1_balanced_augmented\", \"techniques_balanced\")\n",
        "hpednn.initialize_model()\n",
        "hpednn.train_model(augment=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
        "\n",
        "hpednn = HpeDnn(\"data\", \"arch2_balanced\", \"techniques_balanced\")\n",
        "hpednn.initialize_model(DnnArch.ARCH2)\n",
        "hpednn.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
        "\n",
        "hpednn = HpeDnn(\"data\", \"arch3_balanced\", \"techniques_balanced\")\n",
        "hpednn.initialize_model(DnnArch.ARCH3)\n",
        "hpednn.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.model import HpeDnn\n",
        "\n",
        "hpednn = HpeDnn(\"data\", \"arch1_full_balanced\")\n",
        "hpednn.execute_train_runs(runs=2, epochs=10, augment=True, balanced=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
        "\n",
        "hpednn = HpeDnn(\"data\", \"arch1_balanced_not_norm\", \"techniques_balanced\")\n",
        "hpednn.initialize_model(DnnArch.ARCH1, normalize=False)\n",
        "hpednn.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
        "\n",
        "hpednn = HpeDnn(\"data\", \"arch1_balanced_dr_0.3\", \"techniques_balanced\")\n",
        "hpednn.initialize_model(DnnArch.ARCH1, dropout_rate=0.3)\n",
        "hpednn.train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir data/runs/hpe_dnn/arch1_balanced/train1/logs/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.hpe_dnn.model import read_data\n",
        "\n",
        "df_path = \"data/df/techniques/train.pkl\"\n",
        "train = read_data(df_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
