{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634b9adb",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19670289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.impute import SimpleImputer\n",
    "from numpy import nan, arange, array\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from numpy import ndarray, mean, float32, ones, array, concatenate, unique\n",
    "from pandas import Series, concat\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from typing import Tuple\n",
    "from glob import glob\n",
    "\n",
    "from src.labels import iterate_valid_labels, find_valid_segments, get_labels_from_video,\\\n",
    "    get_labels_as_dataframe, value_to_name\n",
    "from src.sampling.landmarks import get_landmark_df_path\n",
    "from src.common.helpers import read_dataframe\n",
    "from src.hpe_dnn.helpers import binarize_labels, unbinarize_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e2a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = read_dataframe(\"data/df/rnn/cvs_features.pkl\")\n",
    "\n",
    "feature_placeholder = ones(shape=(all_features.shape[0]))\n",
    "groups = all_features[\"group\"]\n",
    "labels = all_features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5fccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: groups=[  0   1   2   3   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  25  26  27  28  29  30  31  32  33  34  37  39  40\n",
      "  41  42  43  44  46  47  48  50  51  52  53  54  55  56  57  58  59  61\n",
      "  62  63  64  65  67  68  69  70  71  72  73  74  75  76  77  80  81  82\n",
      "  83  87  88  89  90  91  93  95  96  97  98  99 101 102 104 106 107 108\n",
      " 109 110 111 113 114 115 116 117 118 119 120 121 122 125 126 127 128 129\n",
      " 131 133 134 135 136 137 138 139 142 144 146 148 149 151 153 154 155 156\n",
      " 157 158 159 160 161 163 164 165 167 168 169 170 172 173 174 175 176 177\n",
      " 178 180 181 182 183 184 186 187 188 189 190 192 193 194 195 196 197 198\n",
      " 199 200 201 202 204 205 206 209 210 211 212 213 214 216 217 219 220 221\n",
      " 222 223 224 225 226 227 228 229]\n",
      "  Val:  groups=[  4  24  35  49  60  79  84  86  92 103 123 140 145 152 171 191 203 208\n",
      " 215 218]\n",
      "  Test:  groups=[ 36  38  45  66  78  85  94 100 105 112 124 130 132 141 143 147 150 162\n",
      " 166 179 185 207]\n",
      "Fold 1:\n",
      "  Train: groups=[  0   1   2   3   4   5   7   9  10  11  15  16  17  18  20  21  22  23\n",
      "  24  25  27  29  30  31  33  34  35  36  37  38  41  42  44  45  46  47\n",
      "  48  49  50  53  54  55  56  57  58  60  62  63  64  65  66  67  68  69\n",
      "  70  71  72  74  75  76  77  78  79  80  82  83  84  85  86  87  88  90\n",
      "  92  93  94  95  96  97  98  99 100 101 103 104 105 107 108 110 111 112\n",
      " 113 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 132\n",
      " 133 134 135 136 137 139 140 141 142 143 144 145 146 147 148 150 151 152\n",
      " 153 154 155 157 158 159 160 162 163 164 165 166 167 168 169 170 171 173\n",
      " 175 176 177 179 182 183 185 186 188 189 190 191 193 195 196 197 198 199\n",
      " 201 202 203 204 205 206 207 208 209 210 211 212 214 215 216 217 218 219\n",
      " 220 221 222 224 225 226 227]\n",
      "  Val:  groups=[  8  12  13  26  40  52  59  61  81  89  91 109 138 156 172 174 184 192\n",
      " 194 213 223 228]\n",
      "  Test:  groups=[  6  14  19  28  32  39  43  51  73 102 106 114 131 149 161 178 180 181\n",
      " 187 200 229]\n",
      "Fold 2:\n",
      "  Train: groups=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  38\n",
      "  39  40  42  43  44  45  46  47  49  50  51  53  54  55  56  58  59  60\n",
      "  61  63  65  66  67  68  69  70  71  72  73  75  78  79  82  83  84  85\n",
      "  86  87  90  91  92  93  94  95  96  99 100 102 103 104 105 106 107 108\n",
      " 110 112 113 114 115 116 117 118 120 121 122 124 125 127 128 129 130 131\n",
      " 133 134 135 136 137 138 139 141 143 144 145 146 148 149 150 151 152 153\n",
      " 154 155 156 157 158 159 161 162 163 164 165 166 167 168 169 170 171 172\n",
      " 173 175 176 177 178 179 181 182 183 184 185 186 187 188 190 192 194 196\n",
      " 197 198 199 200 201 202 203 206 207 208 209 213 217 218 219 220 221 222\n",
      " 223 224 225 226 227 228 229]\n",
      "  Val:  groups=[ 14  41  57  74  76  80  81  89 119 132 147 160 180 189 195 210 211 212\n",
      " 214 215]\n",
      "  Test:  groups=[ 16  37  48  52  62  64  77  88  97  98 101 109 111 123 126 140 142 174\n",
      " 191 193 204 205 216]\n",
      "Fold 3:\n",
      "  Train: groups=[  0   1   2   3   4   5   6   8   9  10  11  12  13  14  15  16  17  19\n",
      "  21  22  23  26  28  31  32  34  35  36  37  38  39  41  42  43  44  45\n",
      "  47  48  49  51  53  55  57  58  59  60  62  63  64  66  67  68  70  71\n",
      "  73  76  77  78  79  81  82  83  84  85  87  88  89  90  91  92  93  94\n",
      "  96  97  98 100 101 102 103 104 105 109 110 111 112 114 115 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 131 132 134 135 136 137 138 140\n",
      " 141 142 143 145 146 148 149 150 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 182\n",
      " 183 185 186 187 188 189 191 193 195 196 197 198 199 200 202 203 205 206\n",
      " 207 209 210 211 213 214 215 216 217 218 219 221 222 224 225 226 227 228\n",
      " 229]\n",
      "  Val:  groups=[  7  20  27  40  46  52  54  72  86 106 107 113 130 133 144 147 151 181\n",
      " 190 194 201 204 208]\n",
      "  Test:  groups=[ 18  24  25  29  30  33  50  56  61  65  69  74  75  80  95  99 108 129\n",
      " 139 152 153 184 192 212 220 223]\n",
      "Fold 4:\n",
      "  Train: groups=[  0   1   2   3   4   6   7   9  10  11  12  13  14  15  17  18  19  22\n",
      "  23  24  25  26  27  28  29  31  32  35  36  37  39  40  42  43  44  45\n",
      "  46  47  48  51  53  54  56  57  58  60  62  63  64  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88\n",
      "  89  90  91  92  93  94  97  98  99 100 101 102 103 104 105 106 108 109\n",
      " 110 111 112 114 115 116 117 118 120 121 122 123 124 125 127 128 129 130\n",
      " 131 132 133 134 136 138 139 140 141 142 143 144 146 147 149 150 151 152\n",
      " 153 154 155 156 157 158 159 161 162 165 166 167 168 171 172 174 175 176\n",
      " 177 178 179 180 181 182 183 184 185 187 188 190 191 192 193 194 196 197\n",
      " 199 200 202 203 204 206 207 208 210 211 212 215 216 217 219 220 221 222\n",
      " 223 224 227 228 229]\n",
      "  Val:  groups=[  5  16  21  30  33  38  50  52  59  61  85  95 119 126 148 164 186 198\n",
      " 201 205 213 218 225]\n",
      "  Test:  groups=[  8  20  34  41  49  55  96 107 113 135 137 145 160 163 169 170 173 189\n",
      " 195 209 214 226]\n",
      "Fold 5:\n",
      "  Train: groups=[  2   3   5   6   8   9  10  11  13  14  16  18  19  20  22  24  25  26\n",
      "  28  29  30  32  33  34  35  36  37  40  43  44  45  48  49  50  51  52\n",
      "  53  54  55  56  58  60  62  63  64  65  66  67  68  69  70  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  85  86  87  88  89  91  92  93  94\n",
      "  95  97  99 100 101 102 103 105 106 108 109 111 112 113 114 115 116 117\n",
      " 118 119 120 123 124 126 127 129 130 131 132 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 149 150 151 152 153 154 157 158 159 160 161 162\n",
      " 163 165 166 167 168 169 170 172 173 174 175 176 177 178 179 180 181 182\n",
      " 183 184 185 186 187 189 191 192 194 195 196 197 198 199 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 222 223\n",
      " 224 226 227 229]\n",
      "  Val:  groups=[  0   1  23  38  39  41  57  61  71  96  98 107 110 121 128 134 155 156\n",
      " 188 193 200]\n",
      "  Test:  groups=[  4   7  12  15  17  21  27  31  42  46  47  59  84  90 104 122 125 133\n",
      " 148 164 171 190 221 225 228]\n",
      "Fold 6:\n",
      "  Train: groups=[  1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  18  19  20\n",
      "  21  22  23  25  27  28  29  30  31  32  33  34  36  37  39  41  42  43\n",
      "  45  46  47  48  49  50  51  53  54  55  56  58  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  74  77  78  79  80  84  85  86  87\n",
      "  88  90  91  93  94  95  96  97  98  99 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 115 116 117 118 121 122 123 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 138 139 140 142 143 144 145 146 147 148 149 150\n",
      " 151 152 153 154 155 157 158 159 160 161 162 163 164 165 168 169 170 171\n",
      " 173 174 177 178 179 180 181 182 183 184 187 188 189 190 191 192 193 194\n",
      " 195 196 197 199 200 201 202 203 204 205 207 208 209 211 212 214 215 216\n",
      " 217 219 220 222 223 224 225 226 227 228 229]\n",
      "  Val:  groups=[  0  17  24  38  52  57  75  92 100 114 124 137 141 166 175 185 221]\n",
      "  Test:  groups=[ 11  26  35  40  44  76  81  82  83  89 119 120 156 167 172 176 186 198\n",
      " 206 210 213 218]\n",
      "Fold 7:\n",
      "  Train: groups=[  0   2   5   6   7   8  11  12  13  14  15  16  17  18  19  20  21  25\n",
      "  26  27  28  29  30  31  32  33  34  35  37  40  41  42  43  44  45  46\n",
      "  47  48  50  51  52  53  55  56  57  58  59  61  62  64  65  66  67  68\n",
      "  69  70  73  74  75  76  77  78  79  80  81  82  84  86  88  89  90  91\n",
      "  94  95  96  99 100 101 102 104 106 107 108 109 111 112 113 114 115 116\n",
      " 117 118 119 120 122 123 124 125 126 128 130 131 132 133 134 135 136 137\n",
      " 139 141 142 143 144 145 146 148 149 150 151 153 156 157 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 197 198 199 200 201 202 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 217 219 220 221 222 223\n",
      " 225 226 227 228]\n",
      "  Val:  groups=[  4  23  24  36  38  39  49  83  85  97  98 103 105 129 140 147 152 191\n",
      " 203 218 229]\n",
      "  Test:  groups=[  1   3   9  10  22  54  60  63  71  72  87  92  93 110 121 127 138 154\n",
      " 155 158 159 177 188 196 224]\n",
      "Fold 8:\n",
      "  Train: groups=[  1   2   3   4   5   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  22  24  25  26  27  30  31  32  33  35  36  37  38  39  40  41  42  43\n",
      "  44  46  47  49  50  51  52  54  55  59  60  61  62  63  64  65  66  69\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 101 102 103 104 105 106 108 109 110\n",
      " 111 112 113 114 117 119 120 121 122 124 125 127 129 130 131 132 133 135\n",
      " 137 138 139 142 143 145 147 148 149 150 151 152 153 154 155 157 158 159\n",
      " 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 176 177 178\n",
      " 179 180 181 183 184 185 187 188 189 190 191 192 193 194 195 196 198 199\n",
      " 200 201 202 203 204 205 206 207 208 210 212 213 214 216 217 218 220 221\n",
      " 223 224 225 227 228 229]\n",
      "  Val:  groups=[  6  21  28  29  34  45  48  53  56  85  96 107 123 126 140 141 144 156\n",
      " 182 186 209 226]\n",
      "  Test:  groups=[  0  13  23  57  58  67  68  70  91 115 116 118 128 134 136 146 175 197\n",
      " 211 215 219 222]\n",
      "Fold 9:\n",
      "  Train: groups=[  0   1   3   4   6   8   9  10  12  13  14  15  16  17  18  19  20  21\n",
      "  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  42  43  44  45  46  47  48  49  51  52  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  78\n",
      "  80  81  82  83  84  85  87  88  90  91  92  93  94  95  96  97  98  99\n",
      " 101 102 104 105 106 107 108 109 111 112 113 116 118 119 120 121 122 124\n",
      " 125 126 127 128 130 131 132 133 134 135 136 137 138 139 142 145 146 147\n",
      " 148 149 152 154 155 156 158 159 160 161 162 163 164 166 167 169 170 171\n",
      " 172 173 174 175 176 178 179 181 184 185 186 187 188 189 190 191 192 193\n",
      " 195 197 198 200 204 205 206 207 209 210 211 212 213 214 215 216 218 220\n",
      " 221 223 224 225 226 228 229]\n",
      "  Val:  groups=[  7  11  50  77  89 100 110 114 115 123 129 140 141 143 150 153 177 180\n",
      " 196 219 222]\n",
      "  Test:  groups=[  2   5  53  79  86 103 117 144 151 157 165 168 182 183 194 199 201 202\n",
      " 203 208 217 227]\n"
     ]
    }
   ],
   "source": [
    "sgkf1 = StratifiedGroupKFold(n_splits=10, shuffle=False)\n",
    "for i, (train_temp, test_index) in enumerate(sgkf1.split(feature_placeholder, labels, groups)):\n",
    "    sgkf2 = StratifiedGroupKFold(n_splits=10, shuffle=False)\n",
    "    train_index, val_index = list(sgkf2.split(train_temp, labels[train_temp], groups[train_temp]))[i]\n",
    "    train_index = train_temp[train_index]\n",
    "    val_index = train_temp[val_index]\n",
    "\n",
    "    train_groups = unique(groups[train_index])\n",
    "    val_groups = unique(groups[val_index])\n",
    "    test_groups = unique(groups[test_index])\n",
    "\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: groups={train_groups}\")\n",
    "    print(f\"  Val:  groups={val_groups}\")\n",
    "    print(f\"  Test:  groups={test_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label_frames(groups: list) -> dict:\n",
    "    label_frame_count = {label: 0 for label in iterate_valid_labels()}\n",
    "    for group in groups:\n",
    "        segment_df = all_features.query(f\"group == {group}\")\n",
    "        labels = segment_df[\"label\"]\n",
    "        label_count = labels.value_counts()\n",
    "        \n",
    "        for key in label_frame_count.keys():\n",
    "            if key in label_count.keys():\n",
    "                label_frame_count[key] += label_count[key]\n",
    "    return label_frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0009ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits (train/val/test):\n",
      "NONE: 81.0% / 9.0% / 10.0%\n",
      "FOOT_SWAP: 81.7% / 8.3% / 10.1%\n",
      "OUTSIDE_FLAG: 81.3% / 8.7% / 10.0%\n",
      "BACK_FLAG: 79.1% / 11.4% / 9.5%\n",
      "INSIDE_FLAG: 80.6% / 9.2% / 10.2%\n",
      "DROP_KNEE: 81.6% / 8.3% / 10.1%\n",
      "CROSS_MIDLINE: 84.5% / 7.0% / 8.5%\n",
      "\n",
      "Totals (train/val/test):\n",
      "NONE: 30608 / 3405 / 3781\n",
      "FOOT_SWAP: 1233 / 125 / 152\n",
      "OUTSIDE_FLAG: 4226 / 454 / 518\n",
      "BACK_FLAG: 2891 / 415 / 349\n",
      "INSIDE_FLAG: 2875 / 327 / 363\n",
      "DROP_KNEE: 3847 / 390 / 478\n",
      "CROSS_MIDLINE: 2137 / 178 / 215\n"
     ]
    }
   ],
   "source": [
    "train_count = count_label_frames(train_groups)\n",
    "val_count = count_label_frames(val_groups)\n",
    "test_count = count_label_frames(test_groups)\n",
    "\n",
    "print(\"Data splits (train/val/test):\")\n",
    "for key in train_count.keys():\n",
    "    total = train_count[key] + val_count[key] + test_count[key]\n",
    "    print(f\"{key}: {train_count[key] / total:.1%} / {val_count[key] / total:.1%} / {test_count[key] / total:.1%}\")\n",
    "\n",
    "print()\n",
    "print(\"Totals (train/val/test):\")\n",
    "for key in train_count.keys():\n",
    "    total = train_count[key] + val_count[key] + test_count[key]\n",
    "    print(f\"{key}: {train_count[key]} / {val_count[key]} / {test_count[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82fadb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_features(features: DataFrame) -> DataFrame:\n",
    "    output = features.copy()\n",
    "    imp = SimpleImputer(missing_values=nan, strategy='constant', fill_value=0, \n",
    "        keep_empty_features=True)\n",
    "    output = DataFrame(imp.fit_transform(output), columns=output.keys())\n",
    "    return output\n",
    "\n",
    "def take_groups(df: DataFrame, groups: list) -> DataFrame:\n",
    "    filtered = list(map(lambda group: df.query(f\"group == {group}\"), groups))\n",
    "    return concat(filtered, axis=0, ignore_index=True)\n",
    "\n",
    "def normalize_features(features: DataFrame, group: Series, train_group: list) -> DataFrame:\n",
    "    temp = concat([features.copy(), group], axis=1)\n",
    "    train_df = take_groups(temp, train_group)\n",
    "    train_df = train_df.drop(\"group\", axis=1)\n",
    "    train_mean = train_df.mean()\n",
    "    train_std = train_df.std()\n",
    "\n",
    "    return (features - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0684a6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from src.labels import name_to_value\n",
    "\n",
    "input_name = Series(list(iterate_valid_labels()))\n",
    "\n",
    "output = binarize_labels(input_name)\n",
    "\n",
    "print(output.values)\n",
    "\n",
    "input_hat = unbinarize_labels(output)\n",
    "print(all(input_hat == input_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c8d6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "\n",
    "    @property\n",
    "    def train_df(self) -> DataFrame:\n",
    "        return take_groups(self.data, self.train_groups)\n",
    "\n",
    "    @property\n",
    "    def val_df(self) -> DataFrame:\n",
    "        return take_groups(self.data, self.val_groups)\n",
    "    \n",
    "    @property\n",
    "    def test_df(self) -> DataFrame:\n",
    "        return take_groups(self.data, self.test_groups)\n",
    "\n",
    "    def __init__(self, input_width: int, label_width: int, shift: int, data: DataFrame,\n",
    "            train_groups: list, val_groups: list, test_groups: list):\n",
    "        df = data.copy()\n",
    "        video = df.pop(\"video\")\n",
    "        frame_num = df.pop(\"frame_num\")\n",
    "        group = df.pop(\"group\")\n",
    "\n",
    "        # Transform labels to model ouputs\n",
    "        labels_str = df.pop('label')\n",
    "        labels_bin = binarize_labels(labels_str)\n",
    "        labels = DataFrame(data=labels_bin, columns=list(iterate_valid_labels()))\n",
    "        self.label_columns = list(iterate_valid_labels())\n",
    "\n",
    "        # Remove missing values and normalize features\n",
    "        df = impute_features(df)\n",
    "        df = normalize_features(df, group, train_groups)\n",
    "\n",
    "        # Store full dataset and splits\n",
    "        self.data = concat([video, frame_num, group, df, labels], axis=1)\n",
    "        self.train_groups = train_groups\n",
    "        self.val_groups = val_groups\n",
    "        self.test_groups = test_groups\n",
    "\n",
    "        # Work out the label column indices.\n",
    "        self.column_indices = {name: i for i, name in enumerate(self.data.columns)}\n",
    "        self.label_columns_indices = {name: i for i, name in enumerate(self.label_columns)}\n",
    "\n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __count_label_frames(self, df: DataFrame) -> dict:\n",
    "        label_frame_count = {label: 0 for label in iterate_valid_labels()}\n",
    "        labels = df[\"label\"]\n",
    "        label_count = labels.value_counts()\n",
    "        \n",
    "        for key in label_frame_count.keys():\n",
    "            if key in label_count.keys():\n",
    "                label_frame_count[key] += label_count[key]\n",
    "\n",
    "        return label_frame_count\n",
    "\n",
    "    def inspect_fold_split(self):\n",
    "        train_df = self.train_df\n",
    "        val_df = self.val_df\n",
    "        test_df = self.test_df\n",
    "        print('All shapes are: (frames, features)')\n",
    "        print(f\"Training data: {train_df.shape}\")\n",
    "        print(f\"Val data: {val_df.shape}\")\n",
    "        print(f\"Test data: {test_df.shape}\")\n",
    "\n",
    "        train_count = self.__count_label_frames(train_df)\n",
    "        val_count = self.__count_label_frames(val_df)\n",
    "        test_count = self.__count_label_frames(test_df)\n",
    "\n",
    "        print(\"Data splits (train/val/test):\")\n",
    "        for key in train_count.keys():\n",
    "            total = train_count[key] + val_count[key] + test_count[key]\n",
    "            print(f\"{key}: {train_count[key] / total:.1%} / {val_count[key] / total:.1%} / {test_count[key] / total:.1%}\")\n",
    "\n",
    "        print()\n",
    "        print(\"Totals (train/val/test):\")\n",
    "        for key in train_count.keys():\n",
    "            total = train_count[key] + val_count[key] + test_count[key]\n",
    "            print(f\"{key}: {train_count[key]} / {val_count[key]} / {test_count[key]}\")\n",
    "\n",
    "    def split_window(self, batch: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        inputs = batch[:, self.input_slice, :]\n",
    "        output = batch[:, self.labels_slice, :]\n",
    "        output = tf.stack([output[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "            axis=-1)\n",
    "        \n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        output.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, output\n",
    "\n",
    "    def get_example(self):\n",
    "        # Stack three slices, the length of the total window.\n",
    "        example_batch = tf.stack([array(self.data[:self.total_window_size]),\n",
    "            array(self.data[100:100+self.total_window_size]),\n",
    "            array(self.data[200:200+self.total_window_size])])\n",
    "\n",
    "        example_inputs, example_ouputs = self.split_window(example_batch)\n",
    "\n",
    "        print('All shapes are: (batch, time, features)')\n",
    "        print(f'Window shape: {example_batch.shape}')\n",
    "        print(f'Inputs shape: {example_inputs.shape}')\n",
    "        print(f'Labels shape: {example_ouputs.shape}')\n",
    "\n",
    "        return example_inputs, example_ouputs\n",
    "\n",
    "    def plot(self, model=None, plot_col='NOSE_x', max_subplots=3):\n",
    "        inputs, labels = self.get_example()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        frame_num_index = self.column_indices['frame_num']\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [act]')\n",
    "            feature_values = inputs[n, :, plot_col_index]\n",
    "            x_axis = inputs[n, :, frame_num_index]\n",
    "            \n",
    "            plt.xlim((x_axis[0], x_axis[-1]+1))\n",
    "            plt.plot(x_axis, feature_values,\n",
    "                label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            label_col_index = plot_col_index\n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "            \n",
    "            label_name = unbinarize_labels(array(labels[n, :, :]))\n",
    "            label_x_position = x_axis[-1] + 0.2\n",
    "            plt.text(label_x_position, mean(feature_values), label_name, c='#2ca02c', \n",
    "                label=\"Label\")\n",
    "            \n",
    "            # plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "            # \tedgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "            # if model is not None:\n",
    "            # \tpredictions = model(inputs)\n",
    "            # \tplt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "            # \t\tmarker='X', edgecolors='k', label='Predictions',\n",
    "            # \t\tc='#ff7f0e', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "\n",
    "        plt.xlabel('Frame number')\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = array(data, dtype=float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=False,\n",
    "            batch_size=1,)\n",
    "\n",
    "        ds = ds.map(self.split_window)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19bf500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total window size: 6\n",
      "Input indices: [0 1 2 3 4]\n",
      "Label indices: [5]\n"
     ]
    }
   ],
   "source": [
    "w1 = WindowGenerator(input_width=5, label_width=1, shift=1, data=all_features, \n",
    "    train_groups=train_groups, val_groups=val_groups, test_groups=test_groups)\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25793616",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = w1.train_df\n",
    "label_frame_count = {label: sum(train_df[label]) for label in iterate_valid_labels()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03eba1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are: (frames, features)\n",
      "Training data: (47875, 124)\n",
      "Val data: (5296, 124)\n",
      "Test data: (5858, 124)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mw1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minspect_fold_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 76\u001b[0m, in \u001b[0;36mWindowGenerator.inspect_fold_split\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m train_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__count_label_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m val_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__count_label_frames(val_df)\n\u001b[1;32m     78\u001b[0m test_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__count_label_frames(test_df)\n",
      "Cell \u001b[0;32mIn[35], line 58\u001b[0m, in \u001b[0;36mWindowGenerator.__count_label_frames\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__count_label_frames\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     57\u001b[0m     label_frame_count \u001b[38;5;241m=\u001b[39m {label: \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m iterate_valid_labels()}\n\u001b[0;32m---> 58\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     59\u001b[0m     label_count \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m label_frame_count\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "w1.inspect_fold_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = w1.make_dataset(w1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06fcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "array(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e763d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "features_melted = temp.melt(var_name=\"Column\", value_name=\"Raw\")\n",
    "ax = sns.violinplot(x=\"Column\", y=\"Raw\", data=features_melted)\n",
    "_ = ax.set_xticklabels(temp.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f143ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from src.common.model import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(ClassificationModel):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee21c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
