{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634b9adb",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19670289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 16:14:45.519807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1768490085.543404  199461 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1768490085.550283  199461 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-15 16:14:45.574536: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded labels\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.impute import SimpleImputer\n",
    "from numpy import nan, arange, array\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from numpy import ndarray, mean, float32, ones, array, concatenate, unique\n",
    "from pandas import Series, concat\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from typing import Tuple\n",
    "from glob import glob\n",
    "\n",
    "from src.labels import iterate_valid_labels, find_valid_segments, get_labels_from_video,\\\n",
    "    get_labels_as_dataframe, value_to_name\n",
    "from src.common.helpers import read_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e2a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = read_dataframe(\"data/df/rnn/cvs_features.pkl\")\n",
    "\n",
    "feature_placeholder = ones(shape=(all_features.shape[0]))\n",
    "groups = all_features[\"group\"]\n",
    "labels = all_features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5fccfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: groups=[  0   1   2   3   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  25  26  27  28  29  30  31  32  33  34  37  39  40\n",
      "  41  42  43  44  46  47  48  50  51  52  53  54  55  56  57  58  59  61\n",
      "  62  63  64  65  67  68  69  70  71  72  73  74  75  76  77  80  81  82\n",
      "  83  87  88  89  90  91  93  95  96  97  98  99 101 102 104 106 107 108\n",
      " 109 110 111 113 114 115 116 117 118 119 120 121 122 125 126 127 128 129\n",
      " 131 133 134 135 136 137 138 139 142 144 146 148 149 151 153 154 155 156\n",
      " 157 158 159 160 161 163 164 165 167 168 169 170 172 173 174 175 176 177\n",
      " 178 180 181 182 183 184 186 187 188 189 190 192 193 194 195 196 197 198\n",
      " 199 200 201 202 204 205 206 209 210 211 212 213 214 216 217 219 220 221\n",
      " 222 223 224 225 226 227 228 229]\n",
      "  Val:  groups=[  4  24  35  49  60  79  84  86  92 103 123 140 145 152 171 191 203 208\n",
      " 215 218]\n",
      "  Test:  groups=[ 36  38  45  66  78  85  94 100 105 112 124 130 132 141 143 147 150 162\n",
      " 166 179 185 207]\n",
      "Fold 1:\n",
      "  Train: groups=[  0   1   2   3   4   5   7   9  10  11  15  16  17  18  20  21  22  23\n",
      "  24  25  27  29  30  31  33  34  35  36  37  38  41  42  44  45  46  47\n",
      "  48  49  50  53  54  55  56  57  58  60  62  63  64  65  66  67  68  69\n",
      "  70  71  72  74  75  76  77  78  79  80  82  83  84  85  86  87  88  90\n",
      "  92  93  94  95  96  97  98  99 100 101 103 104 105 107 108 110 111 112\n",
      " 113 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 132\n",
      " 133 134 135 136 137 139 140 141 142 143 144 145 146 147 148 150 151 152\n",
      " 153 154 155 157 158 159 160 162 163 164 165 166 167 168 169 170 171 173\n",
      " 175 176 177 179 182 183 185 186 188 189 190 191 193 195 196 197 198 199\n",
      " 201 202 203 204 205 206 207 208 209 210 211 212 214 215 216 217 218 219\n",
      " 220 221 222 224 225 226 227]\n",
      "  Val:  groups=[  8  12  13  26  40  52  59  61  81  89  91 109 138 156 172 174 184 192\n",
      " 194 213 223 228]\n",
      "  Test:  groups=[  6  14  19  28  32  39  43  51  73 102 106 114 131 149 161 178 180 181\n",
      " 187 200 229]\n",
      "Fold 2:\n",
      "  Train: groups=[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  38\n",
      "  39  40  42  43  44  45  46  47  49  50  51  53  54  55  56  58  59  60\n",
      "  61  63  65  66  67  68  69  70  71  72  73  75  78  79  82  83  84  85\n",
      "  86  87  90  91  92  93  94  95  96  99 100 102 103 104 105 106 107 108\n",
      " 110 112 113 114 115 116 117 118 120 121 122 124 125 127 128 129 130 131\n",
      " 133 134 135 136 137 138 139 141 143 144 145 146 148 149 150 151 152 153\n",
      " 154 155 156 157 158 159 161 162 163 164 165 166 167 168 169 170 171 172\n",
      " 173 175 176 177 178 179 181 182 183 184 185 186 187 188 190 192 194 196\n",
      " 197 198 199 200 201 202 203 206 207 208 209 213 217 218 219 220 221 222\n",
      " 223 224 225 226 227 228 229]\n",
      "  Val:  groups=[ 14  41  57  74  76  80  81  89 119 132 147 160 180 189 195 210 211 212\n",
      " 214 215]\n",
      "  Test:  groups=[ 16  37  48  52  62  64  77  88  97  98 101 109 111 123 126 140 142 174\n",
      " 191 193 204 205 216]\n",
      "Fold 3:\n",
      "  Train: groups=[  0   1   2   3   4   5   6   8   9  10  11  12  13  14  15  16  17  19\n",
      "  21  22  23  26  28  31  32  34  35  36  37  38  39  41  42  43  44  45\n",
      "  47  48  49  51  53  55  57  58  59  60  62  63  64  66  67  68  70  71\n",
      "  73  76  77  78  79  81  82  83  84  85  87  88  89  90  91  92  93  94\n",
      "  96  97  98 100 101 102 103 104 105 109 110 111 112 114 115 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 131 132 134 135 136 137 138 140\n",
      " 141 142 143 145 146 148 149 150 154 155 156 157 158 159 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 182\n",
      " 183 185 186 187 188 189 191 193 195 196 197 198 199 200 202 203 205 206\n",
      " 207 209 210 211 213 214 215 216 217 218 219 221 222 224 225 226 227 228\n",
      " 229]\n",
      "  Val:  groups=[  7  20  27  40  46  52  54  72  86 106 107 113 130 133 144 147 151 181\n",
      " 190 194 201 204 208]\n",
      "  Test:  groups=[ 18  24  25  29  30  33  50  56  61  65  69  74  75  80  95  99 108 129\n",
      " 139 152 153 184 192 212 220 223]\n",
      "Fold 4:\n",
      "  Train: groups=[  0   1   2   3   4   6   7   9  10  11  12  13  14  15  17  18  19  22\n",
      "  23  24  25  26  27  28  29  31  32  35  36  37  39  40  42  43  44  45\n",
      "  46  47  48  51  53  54  56  57  58  60  62  63  64  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88\n",
      "  89  90  91  92  93  94  97  98  99 100 101 102 103 104 105 106 108 109\n",
      " 110 111 112 114 115 116 117 118 120 121 122 123 124 125 127 128 129 130\n",
      " 131 132 133 134 136 138 139 140 141 142 143 144 146 147 149 150 151 152\n",
      " 153 154 155 156 157 158 159 161 162 165 166 167 168 171 172 174 175 176\n",
      " 177 178 179 180 181 182 183 184 185 187 188 190 191 192 193 194 196 197\n",
      " 199 200 202 203 204 206 207 208 210 211 212 215 216 217 219 220 221 222\n",
      " 223 224 227 228 229]\n",
      "  Val:  groups=[  5  16  21  30  33  38  50  52  59  61  85  95 119 126 148 164 186 198\n",
      " 201 205 213 218 225]\n",
      "  Test:  groups=[  8  20  34  41  49  55  96 107 113 135 137 145 160 163 169 170 173 189\n",
      " 195 209 214 226]\n",
      "Fold 5:\n",
      "  Train: groups=[  2   3   5   6   8   9  10  11  13  14  16  18  19  20  22  24  25  26\n",
      "  28  29  30  32  33  34  35  36  37  40  43  44  45  48  49  50  51  52\n",
      "  53  54  55  56  58  60  62  63  64  65  66  67  68  69  70  72  73  74\n",
      "  75  76  77  78  79  80  81  82  83  85  86  87  88  89  91  92  93  94\n",
      "  95  97  99 100 101 102 103 105 106 108 109 111 112 113 114 115 116 117\n",
      " 118 119 120 123 124 126 127 129 130 131 132 135 136 137 138 139 140 141\n",
      " 142 143 144 145 146 147 149 150 151 152 153 154 157 158 159 160 161 162\n",
      " 163 165 166 167 168 169 170 172 173 174 175 176 177 178 179 180 181 182\n",
      " 183 184 185 186 187 189 191 192 194 195 196 197 198 199 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 222 223\n",
      " 224 226 227 229]\n",
      "  Val:  groups=[  0   1  23  38  39  41  57  61  71  96  98 107 110 121 128 134 155 156\n",
      " 188 193 200]\n",
      "  Test:  groups=[  4   7  12  15  17  21  27  31  42  46  47  59  84  90 104 122 125 133\n",
      " 148 164 171 190 221 225 228]\n",
      "Fold 6:\n",
      "  Train: groups=[  1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  18  19  20\n",
      "  21  22  23  25  27  28  29  30  31  32  33  34  36  37  39  41  42  43\n",
      "  45  46  47  48  49  50  51  53  54  55  56  58  59  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  74  77  78  79  80  84  85  86  87\n",
      "  88  90  91  93  94  95  96  97  98  99 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 115 116 117 118 121 122 123 125 126 127 128 129 130\n",
      " 131 132 133 134 135 136 138 139 140 142 143 144 145 146 147 148 149 150\n",
      " 151 152 153 154 155 157 158 159 160 161 162 163 164 165 168 169 170 171\n",
      " 173 174 177 178 179 180 181 182 183 184 187 188 189 190 191 192 193 194\n",
      " 195 196 197 199 200 201 202 203 204 205 207 208 209 211 212 214 215 216\n",
      " 217 219 220 222 223 224 225 226 227 228 229]\n",
      "  Val:  groups=[  0  17  24  38  52  57  75  92 100 114 124 137 141 166 175 185 221]\n",
      "  Test:  groups=[ 11  26  35  40  44  76  81  82  83  89 119 120 156 167 172 176 186 198\n",
      " 206 210 213 218]\n",
      "Fold 7:\n",
      "  Train: groups=[  0   2   5   6   7   8  11  12  13  14  15  16  17  18  19  20  21  25\n",
      "  26  27  28  29  30  31  32  33  34  35  37  40  41  42  43  44  45  46\n",
      "  47  48  50  51  52  53  55  56  57  58  59  61  62  64  65  66  67  68\n",
      "  69  70  73  74  75  76  77  78  79  80  81  82  84  86  88  89  90  91\n",
      "  94  95  96  99 100 101 102 104 106 107 108 109 111 112 113 114 115 116\n",
      " 117 118 119 120 122 123 124 125 126 128 130 131 132 133 134 135 136 137\n",
      " 139 141 142 143 144 145 146 148 149 150 151 153 156 157 160 161 162 163\n",
      " 164 165 166 167 168 169 170 171 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 197 198 199 200 201 202 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 217 219 220 221 222 223\n",
      " 225 226 227 228]\n",
      "  Val:  groups=[  4  23  24  36  38  39  49  83  85  97  98 103 105 129 140 147 152 191\n",
      " 203 218 229]\n",
      "  Test:  groups=[  1   3   9  10  22  54  60  63  71  72  87  92  93 110 121 127 138 154\n",
      " 155 158 159 177 188 196 224]\n",
      "Fold 8:\n",
      "  Train: groups=[  1   2   3   4   5   7   8   9  10  11  12  14  15  16  17  18  19  20\n",
      "  22  24  25  26  27  30  31  32  33  35  36  37  38  39  40  41  42  43\n",
      "  44  46  47  49  50  51  52  54  55  59  60  61  62  63  64  65  66  69\n",
      "  71  72  73  74  75  76  77  78  79  80  81  82  83  84  86  87  88  89\n",
      "  90  92  93  94  95  97  98  99 100 101 102 103 104 105 106 108 109 110\n",
      " 111 112 113 114 117 119 120 121 122 124 125 127 129 130 131 132 133 135\n",
      " 137 138 139 142 143 145 147 148 149 150 151 152 153 154 155 157 158 159\n",
      " 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 176 177 178\n",
      " 179 180 181 183 184 185 187 188 189 190 191 192 193 194 195 196 198 199\n",
      " 200 201 202 203 204 205 206 207 208 210 212 213 214 216 217 218 220 221\n",
      " 223 224 225 227 228 229]\n",
      "  Val:  groups=[  6  21  28  29  34  45  48  53  56  85  96 107 123 126 140 141 144 156\n",
      " 182 186 209 226]\n",
      "  Test:  groups=[  0  13  23  57  58  67  68  70  91 115 116 118 128 134 136 146 175 197\n",
      " 211 215 219 222]\n",
      "Fold 9:\n",
      "  Train: groups=[  0   1   3   4   6   8   9  10  12  13  14  15  16  17  18  19  20  21\n",
      "  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  40  41  42  43  44  45  46  47  48  49  51  52  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  78\n",
      "  80  81  82  83  84  85  87  88  90  91  92  93  94  95  96  97  98  99\n",
      " 101 102 104 105 106 107 108 109 111 112 113 116 118 119 120 121 122 124\n",
      " 125 126 127 128 130 131 132 133 134 135 136 137 138 139 142 145 146 147\n",
      " 148 149 152 154 155 156 158 159 160 161 162 163 164 166 167 169 170 171\n",
      " 172 173 174 175 176 178 179 181 184 185 186 187 188 189 190 191 192 193\n",
      " 195 197 198 200 204 205 206 207 209 210 211 212 213 214 215 216 218 220\n",
      " 221 223 224 225 226 228 229]\n",
      "  Val:  groups=[  7  11  50  77  89 100 110 114 115 123 129 140 141 143 150 153 177 180\n",
      " 196 219 222]\n",
      "  Test:  groups=[  2   5  53  79  86 103 117 144 151 157 165 168 182 183 194 199 201 202\n",
      " 203 208 217 227]\n"
     ]
    }
   ],
   "source": [
    "sgkf1 = StratifiedGroupKFold(n_splits=10, shuffle=False)\n",
    "for i, (train_temp, test_index) in enumerate(sgkf1.split(feature_placeholder, labels, groups)):\n",
    "    sgkf2 = StratifiedGroupKFold(n_splits=10, shuffle=False)\n",
    "    train_index, val_index = list(sgkf2.split(train_temp, labels[train_temp], groups[train_temp]))[i]\n",
    "    train_index = train_temp[train_index]\n",
    "    val_index = train_temp[val_index]\n",
    "\n",
    "    train_groups = unique(groups[train_index])\n",
    "    val_groups = unique(groups[val_index])\n",
    "    test_groups = unique(groups[test_index])\n",
    "\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: groups={train_groups}\")\n",
    "    print(f\"  Val:  groups={val_groups}\")\n",
    "    print(f\"  Test:  groups={test_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "941a5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label_frames(groups: list) -> dict:\n",
    "    label_frame_count = {label: 0 for label in iterate_valid_labels()}\n",
    "    for group in groups:\n",
    "        segment_df = all_features.query(f\"group == {group}\")\n",
    "        labels = segment_df[\"label\"]\n",
    "        label_count = labels.value_counts()\n",
    "        \n",
    "        for key in label_frame_count.keys():\n",
    "            if key in label_count.keys():\n",
    "                label_frame_count[key] += label_count[key]\n",
    "    return label_frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0009ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits (train/val/test):\n",
      "NONE: 81.0% / 9.0% / 10.0%\n",
      "FOOT_SWAP: 81.7% / 8.3% / 10.1%\n",
      "OUTSIDE_FLAG: 81.3% / 8.7% / 10.0%\n",
      "BACK_FLAG: 79.1% / 11.4% / 9.5%\n",
      "INSIDE_FLAG: 80.6% / 9.2% / 10.2%\n",
      "DROP_KNEE: 81.6% / 8.3% / 10.1%\n",
      "CROSS_MIDLINE: 84.5% / 7.0% / 8.5%\n",
      "\n",
      "Totals (train/val/test):\n",
      "NONE: 30608 / 3405 / 3781\n",
      "FOOT_SWAP: 1233 / 125 / 152\n",
      "OUTSIDE_FLAG: 4226 / 454 / 518\n",
      "BACK_FLAG: 2891 / 415 / 349\n",
      "INSIDE_FLAG: 2875 / 327 / 363\n",
      "DROP_KNEE: 3847 / 390 / 478\n",
      "CROSS_MIDLINE: 2137 / 178 / 215\n"
     ]
    }
   ],
   "source": [
    "train_count = count_label_frames(train_groups)\n",
    "val_count = count_label_frames(val_groups)\n",
    "test_count = count_label_frames(test_groups)\n",
    "\n",
    "print(\"Data splits (train/val/test):\")\n",
    "for key in train_count.keys():\n",
    "    total = train_count[key] + val_count[key] + test_count[key]\n",
    "    print(f\"{key}: {train_count[key] / total:.1%} / {val_count[key] / total:.1%} / {test_count[key] / total:.1%}\")\n",
    "\n",
    "print()\n",
    "print(\"Totals (train/val/test):\")\n",
    "for key in train_count.keys():\n",
    "    total = train_count[key] + val_count[key] + test_count[key]\n",
    "    print(f\"{key}: {train_count[key]} / {val_count[key]} / {test_count[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd058aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"data/videos/Route9Climb1.mp4\"\n",
    "label_path = get_labels_from_video(video_path)\n",
    "hpe_path = get_landmark_df_path(video_path)\n",
    "\n",
    "valids = find_valid_segments(label_path)\n",
    "df = read_dataframe(hpe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beda25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_segments = []\n",
    "for valid_segment_idx in valids:\n",
    "    valid_segment_slice = slice(valid_segment_idx[0], valid_segment_idx[1])\n",
    "    valid_segments.append(df[valid_segment_slice])\n",
    "\n",
    "print(f\"Valid segments: {len(valid_segments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783127f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: replace with iteration over all valid segments\n",
    "temp = valid_segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fadb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_features(features: DataFrame) -> DataFrame:\n",
    "\toutput = features.copy()\n",
    "\timp = SimpleImputer(missing_values=nan, strategy='constant', fill_value=0, \n",
    "\t\tkeep_empty_features=True)\n",
    "\toutput = DataFrame(imp.fit_transform(output), columns=output.keys())\n",
    "\treturn output\n",
    "\n",
    "def normalize_features(train_df: DataFrame, val_df: DataFrame, test_df: DataFrame):\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45adf330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: reuse from src.hpe_dnn.helpers\n",
    "def binarize_labels(labels: Series) -> ndarray:\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(list(iterate_valid_labels()))\n",
    "    return encoder.transform(labels)\n",
    "\n",
    "def unbinarize_labels(logits: Series):\n",
    "    encoder = LabelBinarizer()\n",
    "    encoder.fit(list(iterate_valid_labels()))\n",
    "    return encoder.inverse_transform(logits)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_length = temp.shape[0]\n",
    "input_width = 5\n",
    "label_width = 1\n",
    "shift = 1\n",
    "total_window_size = input_width + shift\n",
    "\n",
    "stride = 1\n",
    "val_offset = 9 # 0 - 9\n",
    "test_offset = (val_offset + 1) % 10\n",
    "\n",
    "spliting_group_width = 2 * total_window_size + (total_window_size + 8*stride)\n",
    "print(spliting_group_width)\n",
    "spliting_range = arange(start=0, stop=segment_length, step=spliting_group_width)\n",
    "spliting_groups = map(lambda start: slice(start, min(start + spliting_group_width, segment_length)), spliting_range)\n",
    "print(list(spliting_groups))\n",
    "\n",
    "\n",
    "window_start = arange(start=0, stop=segment_length-total_window_size, step=stride)\n",
    "windows = map(lambda start: slice(start, start+total_window_size), window_start)\n",
    "\n",
    "train_windows = []\n",
    "val_windows = []\n",
    "test_windows = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff4f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(spliting_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8d6246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "\tdef __init__(self, input_width: int, label_width: int, shift: int, valid_segment: DataFrame):\n",
    "\t\t# Store the raw data.\n",
    "\t\tdf = valid_segment.copy()\n",
    "\n",
    "\t\tframe_num = df.pop(\"frame_num\")\n",
    "\n",
    "\t\t# Transform labels to model ouputs\n",
    "\t\tlabels_str = df.pop('label')\n",
    "\t\tlabels_bin = binarize_labels(labels_str)\n",
    "\t\tlabels = DataFrame(data=labels_bin, columns=list(iterate_valid_labels()))\n",
    "\t\t\n",
    "\t\t# Remaining columns are the input features\n",
    "\t\tfeatures = impute_features(df)\n",
    "\n",
    "\t\tself.data = concat([frame_num, features, labels], axis=1)\n",
    "\t\tself.label_columns = list(iterate_valid_labels())\n",
    "\n",
    "\t\t# Work out the label column indices.\n",
    "\t\tself.column_indices = {name: i for i, name in enumerate(self.data.columns)}\n",
    "\t\tself.label_columns_indices = {name: i for i, name in enumerate(self.label_columns)}\n",
    "\n",
    "\t\t# Work out the window parameters.\n",
    "\t\tself.input_width = input_width\n",
    "\t\tself.label_width = label_width\n",
    "\t\tself.shift = shift\n",
    "\n",
    "\t\tself.total_window_size = input_width + shift\n",
    "\n",
    "\t\tself.input_slice = slice(0, input_width)\n",
    "\t\tself.input_indices = arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "\t\tself.label_start = self.total_window_size - self.label_width\n",
    "\t\tself.labels_slice = slice(self.label_start, None)\n",
    "\t\tself.label_indices = arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "\tdef get_splits(self, test_offset: int):\n",
    "\t\t\"\"\"Generate array of slices for the training, validation and test sets.\n",
    "\t\tUsing a 80/10/10 data split.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\ttest_offset (int): Offset of the test slices\n",
    "\t\t\"\"\"\n",
    "\t\tsegment_length = temp.shape[0]\n",
    "\n",
    "\tdef split_window(self, example_batch: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "\t\tinputs = example_batch[:, self.input_slice, :]\n",
    "\t\toutput = example_batch[:, self.labels_slice, :]\n",
    "\t\toutput = tf.stack([output[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "\t\t\taxis=-1)\n",
    "\t\t\n",
    "\t\t# Slicing doesn't preserve static shape information, so set the shapes\n",
    "\t\t# manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "\t\tinputs.set_shape([None, self.input_width, None])\n",
    "\t\toutput.set_shape([None, self.label_width, None])\n",
    "\n",
    "\t\treturn inputs, output\n",
    "\n",
    "\tdef get_example(self):\n",
    "\t\t# Stack three slices, the length of the total window.\n",
    "\t\texample_batch = tf.stack([array(self.data[:self.total_window_size]),\n",
    "\t\t\tarray(self.data[100:100+self.total_window_size]),\n",
    "\t\t\tarray(self.data[200:200+self.total_window_size])])\n",
    "\n",
    "\t\texample_inputs, example_ouputs = self.split_window(example_batch)\n",
    "\n",
    "\t\tprint('All shapes are: (batch, time, features)')\n",
    "\t\tprint(f'Window shape: {example_batch.shape}')\n",
    "\t\tprint(f'Inputs shape: {example_inputs.shape}')\n",
    "\t\tprint(f'Labels shape: {example_ouputs.shape}')\n",
    "\n",
    "\t\treturn example_inputs, example_ouputs\n",
    "\n",
    "\tdef plot(self, model=None, plot_col='NOSE_x', max_subplots=3):\n",
    "\t\tinputs, labels = self.get_example()\n",
    "\t\tplt.figure(figsize=(12, 8))\n",
    "\t\tplot_col_index = self.column_indices[plot_col]\n",
    "\t\tframe_num_index = self.column_indices['frame_num']\n",
    "\t\tmax_n = min(max_subplots, len(inputs))\n",
    "\t\tfor n in range(max_n):\n",
    "\t\t\tplt.subplot(max_n, 1, n+1)\n",
    "\t\t\tplt.ylabel(f'{plot_col} [act]')\n",
    "\t\t\tfeature_values = inputs[n, :, plot_col_index]\n",
    "\t\t\tx_axis = inputs[n, :, frame_num_index]\n",
    "\t\t\t\n",
    "\t\t\tplt.xlim((x_axis[0], x_axis[-1]+1))\n",
    "\t\t\tplt.plot(x_axis, feature_values,\n",
    "\t\t\t\tlabel='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "\t\t\tlabel_col_index = plot_col_index\n",
    "\t\t\tif label_col_index is None:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tlabel_name = unbinarize_labels(array(labels[n, :, :]))\n",
    "\t\t\tlabel_x_position = x_axis[-1] + 0.2\n",
    "\t\t\tplt.text(label_x_position, mean(feature_values), label_name, c='#2ca02c', \n",
    "\t\t\t\tlabel=\"Label\")\n",
    "\t\t\t\n",
    "\t\t\t# plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "\t\t\t# \tedgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "\t\t\t# if model is not None:\n",
    "\t\t\t# \tpredictions = model(inputs)\n",
    "\t\t\t# \tplt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "\t\t\t# \t\tmarker='X', edgecolors='k', label='Predictions',\n",
    "\t\t\t# \t\tc='#ff7f0e', s=64)\n",
    "\n",
    "\t\t\tif n == 0:\n",
    "\t\t\t\tplt.legend()\n",
    "\n",
    "\t\tplt.xlabel('Frame number')\n",
    "\n",
    "\tdef make_dataset(self, data):\n",
    "\t\tdata = array(data, dtype=float32)\n",
    "\t\tds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "\t\t\tdata=data,\n",
    "\t\t\ttargets=None,\n",
    "\t\t\tsequence_length=self.total_window_size,\n",
    "\t\t\tsequence_stride=1,\n",
    "\t\t\tshuffle=False,\n",
    "\t\t\tbatch_size=1,)\n",
    "\n",
    "\t\tds = ds.map(self.split_window)\n",
    "\n",
    "\t\treturn ds\n",
    "\n",
    "\tdef __repr__(self):\n",
    "\t\treturn '\\n'.join([\n",
    "\t\t\tf'Total window size: {self.total_window_size}',\n",
    "\t\t\tf'Input indices: {self.input_indices}',\n",
    "\t\t\tf'Label indices: {self.label_indices}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(input_width=5, label_width=1, shift=1, valid_segment=temp)\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd5fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = w1.make_dataset(w1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06fcb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "array(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing, do this in the training pipeline, determine values only from training data\n",
    "train_mean = temp.mean()\n",
    "train_std = temp.std()\n",
    "\n",
    "temp = (temp - train_mean) / train_std\n",
    "#temp_val = ...\n",
    "#temp_test = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e763d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "features_melted = temp.melt(var_name=\"Column\", value_name=\"Raw\")\n",
    "ax = sns.violinplot(x=\"Column\", y=\"Raw\", data=features_melted)\n",
    "_ = ax.set_xticklabels(temp.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f143ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from src.common.model import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(ClassificationModel):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee21c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
