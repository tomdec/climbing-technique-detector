{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634b9adb",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19670289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ones, unique\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from src.common.helpers import read_dataframe\n",
    "from src.rnn.data import WindowGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = read_dataframe(\"data/df/rnn/cvs_features.pkl\")\n",
    "\n",
    "feature_placeholder = ones(shape=(all_features.shape[0]))\n",
    "groups = all_features[\"group\"]\n",
    "labels = all_features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aef57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 1 # range 1 - 10\n",
    "sgkf1 = StratifiedGroupKFold(n_splits=10, shuffle=False)\n",
    "#for i, (train_temp, test_index) in enumerate(sgkf1.split(feature_placeholder, labels, groups)):\n",
    "train_temp, test_index = list(sgkf1.split(feature_placeholder, labels, groups))[fold_num-1]\n",
    "\n",
    "sgkf2 = StratifiedGroupKFold(n_splits=10, shuffle=False)\n",
    "train_index, val_index = list(sgkf2.split(train_temp, labels[train_temp], groups[train_temp]))[fold_num-1]\n",
    "train_index = train_temp[train_index]\n",
    "val_index = train_temp[val_index]\n",
    "\n",
    "train_groups = unique(groups[train_index])\n",
    "val_groups = unique(groups[val_index])\n",
    "test_groups = unique(groups[test_index])\n",
    "\n",
    "print(f\"Fold {fold_num}:\")\n",
    "print(f\"  Train: groups={train_groups}\")\n",
    "print(f\"  Val:  groups={val_groups}\")\n",
    "print(f\"  Test:  groups={test_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(input_width=5, label_width=1, shift=1, data=all_features, \n",
    "    train_groups=train_groups, val_groups=val_groups, test_groups=test_groups)\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eba1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.inspect_fold_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c067b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.api.models import Sequential, Model\n",
    "from keras.api.layers import LSTM, Dense, Reshape\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.losses import CategoricalCrossentropy\n",
    "from keras.api.metrics import CategoricalAccuracy\n",
    "\n",
    "from src.labels import get_valid_label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457cf7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential([\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dense(units=get_valid_label_count(), activation=\"softmax\"),\n",
    "    Reshape((-1, get_valid_label_count()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model: Model, window: WindowGenerator, patience=3):\n",
    "    early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=patience)\n",
    "\n",
    "    model.compile(loss=CategoricalCrossentropy(), optimizer=Adam(), metrics=[CategoricalAccuracy()])\n",
    "\n",
    "    history = model.fit(window.train_ds, epochs=5, validation_data=window.val_ds, \n",
    "        callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72090958",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = compile_and_fit(lstm_model, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a271d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.plot(lstm_model, plot_col=\"RIGHT_KNEE_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb987987",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = lstm_model.evaluate(w1.test_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f143ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Optional, override\n",
    "\n",
    "from src.common.model import ClassificationModel, ModelConstructorArgs, ModelInitializeArgs,\\\n",
    "    TrainArgs, MultiRunTrainArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnArch(Enum):\n",
    "    ARCH1 = 0\n",
    "\n",
    "class RnnConstructorArgs(ModelConstructorArgs):\n",
    "\n",
    "    @property\n",
    "    def window_generator(self) -> WindowGenerator:\n",
    "        return self._window_generator\n",
    "\n",
    "    @override\n",
    "    def model_arch(self) -> RnnArch:\n",
    "        return self._model_arch\n",
    "    \n",
    "    @override\n",
    "    def __init__(self, name: str, model_arch: RnnArch, window_generator: WindowGenerator,\n",
    "            data_root_path = \"data\", dataset_name = \"techniques\"):\n",
    "        super().__init__(name, model_arch, data_root_path, dataset_name)\n",
    "        self._window_generator = window_generator\n",
    "\n",
    "class RnnTrainArgs(TrainArgs):\n",
    "\n",
    "    @override\n",
    "    @property\n",
    "    def balance(self) -> bool:\n",
    "        \"\"\"Rnn models are never trained on balanced data.\"\"\"\n",
    "        return False\n",
    "    \n",
    "    def __init__(self, epochs=10, additional_config={}):\n",
    "        super().__init__(epochs, False, additional_config)\n",
    "\n",
    "class RnnModelInitializeArgs(ModelInitializeArgs):\n",
    "    pass\n",
    "\n",
    "class RnnMultiRunTrainArgs(MultiRunTrainArgs):\n",
    "    \n",
    "    @override\n",
    "    @property\n",
    "    def model_initialize_args(self) -> RnnModelInitializeArgs:\n",
    "        \"\"\"Arguments for initializing the HPE DNN model.\"\"\"\n",
    "        return self._model_initialize_args\n",
    "    \n",
    "    @override\n",
    "    def __init__(self, model_initialize_args: RnnModelInitializeArgs, \n",
    "            runs = 5, \n",
    "            train_args: RnnTrainArgs = RnnTrainArgs()):\n",
    "        super().__init__(model_initialize_args, runs, train_args)\n",
    "\n",
    "class Rnn(ClassificationModel):\n",
    "    \n",
    "    @override\n",
    "    @property\n",
    "    def model_arch(self) -> RnnArch:\n",
    "        \"\"\"Enum that is mapped to a factory function\"\"\"\n",
    "        return self._model_arch\n",
    "    \n",
    "    @override\n",
    "    def __init__(self, args: RnnConstructorArgs):\n",
    "        super().__init__(args)\n",
    "\n",
    "    @override\n",
    "    def execute_train_runs(self, args: RnnMultiRunTrainArgs):\n",
    "        return super().execute_train_runs(args)\n",
    "\n",
    "    @override\n",
    "    def initialize_model(self, args: RnnModelInitializeArgs):\n",
    "        ClassificationModel.initialize_model(self, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee21c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
