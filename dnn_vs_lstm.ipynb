{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634b9adb",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from numpy import (\n",
    "    ones,\n",
    "    unique,\n",
    "    ndarray,\n",
    "    save, \n",
    "    load,\n",
    "    average\n",
    ")\n",
    "from typing import Tuple, Iterator, List, override\n",
    "from ctypes import ArgumentError\n",
    "from os import makedirs\n",
    "from os.path import join, exists\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.common.helpers import read_dataframe\n",
    "from src.common.model import MultiRunTrainArgs, TrainArgs\n",
    "from src.rnn.architecture import RnnArch\n",
    "from src.rnn.data import WindowGenerator\n",
    "from src.rnn.model import Rnn, RnnConstructorArgs, RnnModelInitializeArgs, RnnTrainArgs,\\\n",
    "    RnnMultiRunTrainArgs, RnnTestArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedStratifiedGroupKFold:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._n_splits = 10\n",
    "        self._shuffle = False\n",
    "\n",
    "        self._splitter = StratifiedGroupKFold(\n",
    "            n_splits=self._n_splits, shuffle=self._shuffle\n",
    "        )\n",
    "\n",
    "        self._splits: List[Tuple[ndarray, ndarray, ndarray]] | None = None\n",
    "\n",
    "    def split(\n",
    "        self, X: DataFrame, y: Series, groups: Series\n",
    "    ) -> Iterator[Tuple[ndarray, ndarray, ndarray]]:\n",
    "\n",
    "        for n in range(self._n_splits):\n",
    "            train_temp, test_index = list(self._splitter.split(X, y, groups))[n]\n",
    "            train_index, val_index = list(\n",
    "                self._splitter.split(train_temp, y[train_temp], groups[train_temp])\n",
    "            )[n]\n",
    "\n",
    "            train_index = train_temp[train_index]\n",
    "            val_index = train_temp[val_index]\n",
    "\n",
    "            yield train_index, val_index, test_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb36db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RnnFoldCrossValidation:\n",
    "\n",
    "    @property\n",
    "    def model_constructor_args(self) -> RnnConstructorArgs:\n",
    "        return self._model_args\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_args: RnnConstructorArgs\n",
    "    ):\n",
    "        self._model_args = model_args\n",
    "        self._splitter = ExtendedStratifiedGroupKFold()\n",
    "\n",
    "    def get_full_data_list(self) -> DataFrame:\n",
    "        path_to_all = join(self.model_constructor_args.data_root_path, \"df\", \"rnn\", \n",
    "            \"cvs_features.pkl\")\n",
    "        return read_dataframe(path_to_all)\n",
    "\n",
    "    def train_folds(self, train_run_args: MultiRunTrainArgs, verbose: bool = False):\n",
    "        full_data = self.get_full_data_list()\n",
    "\n",
    "        feature_placeholder = ones(shape=(full_data.shape[0]))\n",
    "        labels = full_data[\"label\"]\n",
    "        groups = full_data[\"group\"]\n",
    "\n",
    "        split_iterator = self._splitter.split(feature_placeholder, labels, groups)\n",
    "\n",
    "        for fold_index, split in enumerate(split_iterator):\n",
    "            train_index, val_index, test_index = split\n",
    "            train_groups = unique(groups[train_index])\n",
    "            val_groups = unique(groups[val_index])\n",
    "            test_groups = unique(groups[test_index])\n",
    "\n",
    "                    \n",
    "            if verbose:\n",
    "                print(f\"Fold {fold_index+1}:\")\n",
    "                print(f\"  Train: groups={train_groups}\")\n",
    "                print(f\"  Val:  groups={val_groups}\")\n",
    "                print(f\"  Test:  groups={test_groups}\")\n",
    "\n",
    "            fold_num = fold_index + 1\n",
    "            self.__train_fold(train_run_args, fold_num, full_data, train_groups, val_groups,\n",
    "                test_groups, verbose)\n",
    "\n",
    "        self.print_box_plot()\n",
    "    \n",
    "    def print_box_plot(self):\n",
    "        metrics = self.get_test_accuracy_metrics()\n",
    "\n",
    "        print(f\"Average Top 1 categorical accuracy: {average(metrics)}\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.boxplot(metrics)\n",
    "        plt.show()\n",
    "\n",
    "    def get_test_accuracy_metrics(self) -> List[float]:\n",
    "        def get_metric(model: Rnn) -> float:\n",
    "            return model.get_test_accuracy_metric()\n",
    "\n",
    "        models = list(map(self.__init_fold_model, range(1, 11)))\n",
    "        return list(map(get_metric, models))\n",
    "\n",
    "    def test_folds(self):\n",
    "        full_data = self.get_full_data_list()\n",
    "\n",
    "        for fold_index in range(self._splitter._n_splits):\n",
    "            fold_num = fold_index + 1\n",
    "\n",
    "            model = self.__init_fold_model(fold_num)\n",
    "            model_dir = model._get_model_dir()\n",
    "\n",
    "            if self.__split_files_exist(model_dir):\n",
    "                (train_groups, val_groups, test_groups) = self.__load_split(model_dir)\n",
    "            else:\n",
    "                raise Exception(\n",
    "                    \"split files should already exist when just testing the models\"\n",
    "                )\n",
    "\n",
    "            wg = self.__build_fold(fold_num, full_data, train_groups, val_groups, test_groups)\n",
    "\n",
    "            additional_config = self.__get_additional_config(\n",
    "                context_config={\"fold\": fold_num}\n",
    "            )\n",
    "            model.test_model(\n",
    "                args=RnnTestArgs(\n",
    "                    window_generator=wg,\n",
    "                    write_to_wandb=True, additional_config=additional_config)\n",
    "            )\n",
    "\n",
    "        self.print_box_plot()\n",
    "\n",
    "    def __get_additional_config(self, context_config: dict = {}) -> dict:\n",
    "        return context_config | {\n",
    "            # add values from model_initialize_args\n",
    "        }\n",
    "            \n",
    "    def __train_fold(self, train_run_args: MultiRunTrainArgs, fold_num: int, data: DataFrame, \n",
    "            train_groups: list, val_groups: list, test_groups: list, verbose: bool):\n",
    "        model = self.__init_fold_model(fold_num)\n",
    "        model_dir = model._get_model_dir()\n",
    "\n",
    "        if self.__split_files_exist(model_dir):\n",
    "            (train_groups, val_groups, test_groups) = self.__load_split(model_dir)\n",
    "        else:\n",
    "            self.__save_split(model_dir, (train_groups, val_groups, test_groups))\n",
    "        \n",
    "        wg = self.__build_fold(fold_num, data, train_groups, val_groups, test_groups, verbose)\n",
    "\n",
    "        additional_config = self.__get_additional_config(\n",
    "            context_config={\"fold\": fold_num}\n",
    "        )\n",
    "        \n",
    "        rnn_train_run_args = RnnMultiRunTrainArgs(\n",
    "            train_args=RnnTrainArgs(\n",
    "                window_generator = wg,\n",
    "                epochs = train_run_args.train_args.epochs,\n",
    "                additional_config = additional_config | train_run_args.train_args.additional_config\n",
    "            ),\n",
    "            runs=train_run_args.runs,\n",
    "        )\n",
    "        model.execute_train_runs(rnn_train_run_args)\n",
    "\n",
    "        model.test_model(\n",
    "            args=RnnTestArgs(window_generator=wg, write_to_wandb=True, \n",
    "                additional_config=additional_config)\n",
    "        )\n",
    "        \n",
    "    def __init_fold_model(self, fold_num: int) -> Rnn:\n",
    "        adapted_args = self._model_args.copy_with(\n",
    "            name=f\"{self._model_args.name}-fold{fold_num}\"\n",
    "        )\n",
    "        return Rnn(adapted_args)\n",
    "\n",
    "    def __split_files_exist(self, model_dir):\n",
    "        return (\n",
    "            exists(join(model_dir, \"split\", \"train.npy\"))\n",
    "            and exists(join(model_dir, \"split\", \"val.npy\"))\n",
    "            and exists(join(model_dir, \"split\", \"test.npy\"))\n",
    "        )\n",
    "\n",
    "    def __load_split(self, model_dir) -> Tuple[ndarray, ndarray, ndarray]:\n",
    "        return (\n",
    "            load(join(model_dir, \"split\", \"train.npy\")),\n",
    "            load(join(model_dir, \"split\", \"val.npy\")),\n",
    "            load(join(model_dir, \"split\", \"test.npy\")),\n",
    "        )\n",
    "\n",
    "    def __save_split(self, model_dir, split: Tuple[ndarray, ndarray, ndarray]):\n",
    "        (train, val, test) = split\n",
    "\n",
    "        makedirs(join(model_dir, \"split\"), exist_ok=True)\n",
    "        save(join(model_dir, \"split\", \"train.npy\"), train)\n",
    "        save(join(model_dir, \"split\", \"val.npy\"), val)\n",
    "        save(join(model_dir, \"split\", \"test.npy\"), test)\n",
    "\n",
    "    def __build_fold(self, fold_num: int, data: DataFrame, train_groups: list, val_groups: list, \n",
    "            test_groups: list, verbose: bool) -> WindowGenerator:\n",
    "        if verbose: print(f\"Building fold {fold_num} ...\")\n",
    "        \n",
    "        wg = WindowGenerator(5, 1, 1, data, train_groups, val_groups, test_groups)\n",
    "        if verbose:\n",
    "            print(wg)\n",
    "            wg.inspect_fold_split()\n",
    "        return wg\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd3fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_folds = RnnFoldCrossValidation(\n",
    "    model_args=RnnConstructorArgs(\n",
    "        name=\"arch1\",\n",
    "        model_initialize_args=RnnModelInitializeArgs(\n",
    "            model_arch=RnnArch.ARCH1\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cfb5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_folds.train_folds(train_run_args=MultiRunTrainArgs(\n",
    "    runs=5,\n",
    "    train_args=TrainArgs(\n",
    "        epochs=10\n",
    "    )\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f92aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_group_split(\n",
    "#     csv_data: DataFrame, split_idx: int, verbose: bool = False\n",
    "# ) -> Tuple[list, list, list]:\n",
    "\n",
    "#     n_splits = 10\n",
    "#     if not (0 <= split_idx and split_idx < n_splits):\n",
    "#         raise Exception(f\"split_idx must be in [0, {n_splits-1}]\")\n",
    "\n",
    "#     feature_placeholder = ones(shape=(csv_data.shape[0]))\n",
    "#     groups = csv_data[\"group\"]\n",
    "#     labels = csv_data[\"label\"]\n",
    "\n",
    "#     sgkf1 = StratifiedGroupKFold(n_splits=n_splits, shuffle=False)\n",
    "#     train_temp, test_index = list(sgkf1.split(feature_placeholder, labels, groups))[\n",
    "#         split_idx\n",
    "#     ]\n",
    "\n",
    "#     train_index, val_index = list(\n",
    "#         sgkf1.split(train_temp, labels[train_temp], groups[train_temp])\n",
    "#     )[split_idx]\n",
    "#     train_index = train_temp[train_index]\n",
    "#     val_index = train_temp[val_index]\n",
    "\n",
    "#     train_groups = unique(groups[train_index])\n",
    "#     val_groups = unique(groups[val_index])\n",
    "#     test_groups = unique(groups[test_index])\n",
    "\n",
    "\n",
    "#     return train_groups, val_groups, test_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da95fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series, concat\n",
    "from numpy import arange\n",
    "from numpy.random import rand, choice\n",
    "\n",
    "from src.labels import iterate_valid_labels\n",
    "from src.rnn.data import get_group_split\n",
    "\n",
    "test_features = DataFrame(rand(100, 20), columns=[f\"feat{n}\" for n in arange(20)])\n",
    "test_groups = Series(arange(0, 100), name=\"group\")\n",
    "test_labels = Series(choice(list(iterate_valid_labels()), 100), name=\"label\")\n",
    "test_all_features = concat([test_features, test_groups, test_labels], axis=1)\n",
    "\n",
    "groups1 = get_group_split(test_all_features, 5)\n",
    "groups2 = get_group_split(test_all_features, 5)\n",
    "\n",
    "print(all(groups1[0]==groups2[0]))\n",
    "print(all(groups1[1]==groups2[1]))\n",
    "print(all(groups1[2]==groups2[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = read_dataframe(\"data/df/rnn/cvs_features.pkl\")\n",
    "\n",
    "feature_placeholder = ones(shape=(all_features.shape[0]))\n",
    "groups = all_features[\"group\"]\n",
    "labels = all_features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aef57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 1 # range 1 - 10\n",
    "sgkf1 = StratifiedGroupKFold(n_splits=10, shuffle=False)\n",
    "#for i, (train_temp, test_index) in enumerate(sgkf1.split(feature_placeholder, labels, groups)):\n",
    "train_temp, test_index = list(sgkf1.split(feature_placeholder, labels, groups))[fold_num-1]\n",
    "\n",
    "sgkf2 = StratifiedGroupKFold(n_splits=10, shuffle=False)\n",
    "train_index, val_index = list(sgkf2.split(train_temp, labels[train_temp], groups[train_temp]))[fold_num-1]\n",
    "train_index = train_temp[train_index]\n",
    "val_index = train_temp[val_index]\n",
    "\n",
    "train_groups = unique(groups[train_index])\n",
    "val_groups = unique(groups[val_index])\n",
    "test_groups = unique(groups[test_index])\n",
    "\n",
    "print(f\"Fold {fold_num}:\")\n",
    "print(f\"  Train: groups={train_groups}\")\n",
    "print(f\"  Val:  groups={val_groups}\")\n",
    "print(f\"  Test:  groups={test_groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd347b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series, concat\n",
    "from numpy import arange\n",
    "from numpy.random import rand, choice\n",
    "\n",
    "from src.labels import iterate_valid_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(input_width=5, label_width=1, shift=1, data=all_features, \n",
    "    train_groups=train_groups, val_groups=val_groups, test_groups=test_groups)\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eba1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.inspect_fold_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad7a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ee21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Rnn(args=RnnConstructorArgs(\n",
    "    name=\"arch1\",\n",
    "    model_initialize_args=RnnModelInitializeArgs(\n",
    "        model_arch=RnnArch.ARCH1\n",
    "    )\n",
    "))\n",
    "rnn.initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77778e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn._get_best_model_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc4699",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.train_model(args=RnnTrainArgs(\n",
    "    window_generator=w1,\n",
    "    epochs=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a271d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.plot(rnn.model, plot_col=\"RIGHT_KNEE_x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
