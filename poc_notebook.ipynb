{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sampling.images import plot_frame_count_distributions\n",
    "\n",
    "samples_root_dir = \"data/samples\"\n",
    "\n",
    "plot_frame_count_distributions(samples_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "\n",
    "    def func():\n",
    "        pass\n",
    "\n",
    "x = Test()\n",
    "x.func.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sota K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Projects/climbing-technique-detector/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for ultralytics v8.0.238 and below.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `yolov8`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 1 ...\n",
      "Fold 1: Train size = 4373, Val size = 568, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtom-decoutere\u001b[0m (\u001b[33mtom-decoutere-open-universiteit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_171149-9k72wjw9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9k72wjw9' target=\"_blank\">yolo11n-cls-f1</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9k72wjw9' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9k72wjw9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f1, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f1/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4373 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 568 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753974728.639051   16333 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753974728.944330   16333 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f1/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4373 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4373/4373 [01:17<00:00, 56.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 568 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 568/568 [00:10<00:00, 53.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f1/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.66G      1.143          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:12<00:00,  3.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:06<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.674      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.08it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 185.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f1/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f1/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f1/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4373 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 568 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.68      0.993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 187.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f1/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.67958</td></tr><tr><td>metrics/accuracy_top5</td><td>0.99296</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.642</td></tr><tr><td>train/loss</td><td>1.14326</td></tr><tr><td>val/loss</td><td>0.90378</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f1</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9k72wjw9' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9k72wjw9</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_171149-9k72wjw9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa81397e240>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8362676203250885\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.6795774698257446, 'metrics/accuracy_top5': 0.9929577708244324, 'fitness': 0.8362676203250885}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f1/train')\n",
      "speed: {'preprocess': 0.44339238916044976, 'inference': 0.6420218309819613, 'loss': 0.00024557924865495784, 'postprocess': 0.0012995070891789304}\n",
      "task: 'classify'\n",
      "top1: 0.6795774698257446\n",
      "top5: 0.9929577708244324\n",
      "loading the model 'yolo11n-cls-f1' with the weights at 'data/runs/sota/yolo11n-cls-f1/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_171653-kfikhbb3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/kfikhbb3' target=\"_blank\">yolo11n-cls-f1</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/kfikhbb3' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/kfikhbb3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4373 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:11<00:00, 48.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:07<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.694      0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.6ms preprocess, 1.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f1/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f1</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/kfikhbb3' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/kfikhbb3</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_171653-kfikhbb3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 2 ...\n",
      "Fold 2: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_172159-q6ttufvz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/q6ttufvz' target=\"_blank\">yolo11n-cls-f2</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/q6ttufvz' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/q6ttufvz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f2, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f2/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f2/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:39<00:00, 43.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:10<00:00, 51.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f2/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.49G       1.15         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:12<00:00,  3.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.688      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.88it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 163.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f2/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f2/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f2/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.695      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 151.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f2/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.69479</td></tr><tr><td>metrics/accuracy_top5</td><td>0.96948</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.638</td></tr><tr><td>train/loss</td><td>1.14986</td></tr><tr><td>val/loss</td><td>0.89971</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f2</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/q6ttufvz' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/q6ttufvz</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_172159-q6ttufvz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa754161520>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8321364521980286\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.6947935223579407, 'metrics/accuracy_top5': 0.9694793820381165, 'fitness': 0.8321364521980286}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f2/train')\n",
      "speed: {'preprocess': 0.4808986841143348, 'inference': 0.638468705543653, 'loss': 0.0030972171492065358, 'postprocess': 0.009792605074309816}\n",
      "task: 'classify'\n",
      "top1: 0.6947935223579407\n",
      "top5: 0.9694793820381165\n",
      "loading the model 'yolo11n-cls-f2' with the weights at 'data/runs/sota/yolo11n-cls-f2/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_172615-lubxjwwc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/lubxjwwc' target=\"_blank\">yolo11n-cls-f2</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/lubxjwwc' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/lubxjwwc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:12<00:00, 43.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:11<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.745      0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f2/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f2</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/lubxjwwc' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/lubxjwwc</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_172615-lubxjwwc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 3 ...\n",
      "Fold 3: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_173136-87rf0zqu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/87rf0zqu' target=\"_blank\">yolo11n-cls-f3</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/87rf0zqu' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/87rf0zqu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f3, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f3/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f3/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:51<00:00, 39.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:13<00:00, 42.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f3/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.55G      1.152         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:09<00:00,  3.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.715      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.84it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 194.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f3/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f3/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f3/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.718      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 177.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f3/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.71813</td></tr><tr><td>metrics/accuracy_top5</td><td>0.96589</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.738</td></tr><tr><td>train/loss</td><td>1.15152</td></tr><tr><td>val/loss</td><td>0.89543</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f3</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/87rf0zqu' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/87rf0zqu</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_173136-87rf0zqu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa801f8be00>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8420107662677765\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.7181328535079956, 'metrics/accuracy_top5': 0.9658886790275574, 'fitness': 0.8420107662677765}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f3/train')\n",
      "speed: {'preprocess': 0.4797053464945018, 'inference': 0.7384544829093923, 'loss': 0.0050148401134338105, 'postprocess': 0.00845243972709446}\n",
      "task: 'classify'\n",
      "top1: 0.7181328535079956\n",
      "top5: 0.9658886790275574\n",
      "loading the model 'yolo11n-cls-f3' with the weights at 'data/runs/sota/yolo11n-cls-f3/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_173613-a6joh2b4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/a6joh2b4' target=\"_blank\">yolo11n-cls-f3</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/a6joh2b4' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/a6joh2b4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:12<00:00, 44.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:08<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.716      0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f3/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f3</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/a6joh2b4' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/a6joh2b4</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_173613-a6joh2b4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 4 ...\n",
      "Fold 4: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_174138-5ez8cctw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/5ez8cctw' target=\"_blank\">yolo11n-cls-f4</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/5ez8cctw' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/5ez8cctw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f4, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f4/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f4/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:51<00:00, 39.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:16<00:00, 33.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f4/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.57G      1.149         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:08<00:00,  4.01it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.671      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.86it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 184.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f4/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f4/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f4/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:06<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.67      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 160.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f4/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.66966</td></tr><tr><td>metrics/accuracy_top5</td><td>0.96948</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.859</td></tr><tr><td>train/loss</td><td>1.1488</td></tr><tr><td>val/loss</td><td>0.91876</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f4</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/5ez8cctw' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/5ez8cctw</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_174138-5ez8cctw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa7bfb627b0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8195691406726837\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.669658899307251, 'metrics/accuracy_top5': 0.9694793820381165, 'fitness': 0.8195691406726837}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f4/train')\n",
      "speed: {'preprocess': 0.4293023374749271, 'inference': 0.8585486805385825, 'loss': 0.00038792093282756084, 'postprocess': 0.0010093986420412306}\n",
      "task: 'classify'\n",
      "top1: 0.669658899307251\n",
      "top5: 0.9694793820381165\n",
      "loading the model 'yolo11n-cls-f4' with the weights at 'data/runs/sota/yolo11n-cls-f4/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_174611-1yl4mvn3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1yl4mvn3' target=\"_blank\">yolo11n-cls-f4</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1yl4mvn3' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1yl4mvn3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:15<00:00, 34.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:09<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.699      0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 1.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f4/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f4</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1yl4mvn3' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1yl4mvn3</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_174611-1yl4mvn3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 5 ...\n",
      "Fold 5: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_175124-6421p8en</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/6421p8en' target=\"_blank\">yolo11n-cls-f5</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/6421p8en' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/6421p8en</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f5, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f5/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f5/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:49<00:00, 39.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:13<00:00, 40.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f5/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.59G      1.143         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:09<00:00,  3.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.688      0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.90it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 181.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.022 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f5/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f5/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f5/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.693      0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 159.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f5/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.693</td></tr><tr><td>metrics/accuracy_top5</td><td>0.97487</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.85</td></tr><tr><td>train/loss</td><td>1.14349</td></tr><tr><td>val/loss</td><td>0.89621</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f5</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/6421p8en' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/6421p8en</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_175124-6421p8en/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa801c81ee0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8339318037033081\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.6929982304573059, 'metrics/accuracy_top5': 0.9748653769493103, 'fitness': 0.8339318037033081}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f5/train')\n",
      "speed: {'preprocess': 0.4497549785121346, 'inference': 0.849523655342898, 'loss': 0.0003036463765270299, 'postprocess': 0.000841192087272259}\n",
      "task: 'classify'\n",
      "top1: 0.6929982304573059\n",
      "top5: 0.9748653769493103\n",
      "loading the model 'yolo11n-cls-f5' with the weights at 'data/runs/sota/yolo11n-cls-f5/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_175549-f2i1x9rl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/f2i1x9rl' target=\"_blank\">yolo11n-cls-f5</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/f2i1x9rl' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/f2i1x9rl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:08<00:00, 63.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:11<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.714      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 1.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f5/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f5</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/f2i1x9rl' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/f2i1x9rl</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_175549-f2i1x9rl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 6 ...\n",
      "Fold 6: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_180052-klu5rr29</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/klu5rr29' target=\"_blank\">yolo11n-cls-f6</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/klu5rr29' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/klu5rr29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f6, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f6/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f6/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:51<00:00, 39.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:13<00:00, 41.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f6/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.44G      1.137         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:08<00:00,  3.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.709      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.75it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 208.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f6/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f6/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f6/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.706      0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 160.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f6/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.70557</td></tr><tr><td>metrics/accuracy_top5</td><td>0.97846</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.745</td></tr><tr><td>train/loss</td><td>1.13672</td></tr><tr><td>val/loss</td><td>0.868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f6</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/klu5rr29' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/klu5rr29</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_180052-klu5rr29/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa7d7b709e0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8420107662677765\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.7055655121803284, 'metrics/accuracy_top5': 0.9784560203552246, 'fitness': 0.8420107662677765}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f6/train')\n",
      "speed: {'preprocess': 0.4538153356197834, 'inference': 0.7446192333385301, 'loss': 0.00028835014520376865, 'postprocess': 0.0007184166118462488}\n",
      "task: 'classify'\n",
      "top1: 0.7055655121803284\n",
      "top5: 0.9784560203552246\n",
      "loading the model 'yolo11n-cls-f6' with the weights at 'data/runs/sota/yolo11n-cls-f6/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_180520-zwv45bxu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/zwv45bxu' target=\"_blank\">yolo11n-cls-f6</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/zwv45bxu' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/zwv45bxu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:16<00:00, 33.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:08<00:00,  4.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.689      0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 1.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f6/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f6</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/zwv45bxu' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/zwv45bxu</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_180520-zwv45bxu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 7 ...\n",
      "Fold 7: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_181034-m4452qpg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/m4452qpg' target=\"_blank\">yolo11n-cls-f7</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/m4452qpg' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/m4452qpg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f7, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f7/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f7/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:50<00:00, 39.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:16<00:00, 34.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f7/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.45G      1.144         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:09<00:00,  3.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.716      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 184.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f7/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f7/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f7/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:06<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.715      0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 181.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f7/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.71454</td></tr><tr><td>metrics/accuracy_top5</td><td>0.96768</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.711</td></tr><tr><td>train/loss</td><td>1.14439</td></tr><tr><td>val/loss</td><td>0.8902</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f7</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/m4452qpg' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/m4452qpg</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_181034-m4452qpg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa81397d3a0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8411131203174591\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.7145422101020813, 'metrics/accuracy_top5': 0.9676840305328369, 'fitness': 0.8411131203174591}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f7/train')\n",
      "speed: {'preprocess': 0.49030278826924967, 'inference': 0.7110661723570734, 'loss': 0.007311922633482053, 'postprocess': 0.003830192259912458}\n",
      "task: 'classify'\n",
      "top1: 0.7145422101020813\n",
      "top5: 0.9676840305328369\n",
      "loading the model 'yolo11n-cls-f7' with the weights at 'data/runs/sota/yolo11n-cls-f7/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_181505-9u3ln9qk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9u3ln9qk' target=\"_blank\">yolo11n-cls-f7</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9u3ln9qk' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9u3ln9qk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:08<00:00, 66.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:08<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.707      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.6ms preprocess, 1.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f7/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f7</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9u3ln9qk' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/9u3ln9qk</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_181505-9u3ln9qk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 8 ...\n",
      "Fold 8: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.5s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_182019-o6og287d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/o6og287d' target=\"_blank\">yolo11n-cls-f8</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/o6og287d' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/o6og287d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f8, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f8/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f8/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:49<00:00, 39.87it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:16<00:00, 33.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f8/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.45G      1.141         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:09<00:00,  3.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.689      0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.93it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 187.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f8/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f8/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f8/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.697      0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 167.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f8/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.69659</td></tr><tr><td>metrics/accuracy_top5</td><td>0.97127</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.89</td></tr><tr><td>train/loss</td><td>1.1415</td></tr><tr><td>val/loss</td><td>0.92227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f8</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/o6og287d' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/o6og287d</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_182019-o6og287d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa886066fc0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8339317739009857\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.6965888738632202, 'metrics/accuracy_top5': 0.9712746739387512, 'fitness': 0.8339317739009857}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f8/train')\n",
      "speed: {'preprocess': 0.4315640503763015, 'inference': 0.8899814022255181, 'loss': 0.000778062796200119, 'postprocess': 0.002283850884151978}\n",
      "task: 'classify'\n",
      "top1: 0.6965888738632202\n",
      "top5: 0.9712746739387512\n",
      "loading the model 'yolo11n-cls-f8' with the weights at 'data/runs/sota/yolo11n-cls-f8/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_182453-nuw8njta</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/nuw8njta' target=\"_blank\">yolo11n-cls-f8</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/nuw8njta' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/nuw8njta</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:08<00:00, 61.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:09<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.709      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f8/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f8</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/nuw8njta' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/nuw8njta</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_182453-nuw8njta/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 9 ...\n",
      "Fold 9: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_183001-y7lutflx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/y7lutflx' target=\"_blank\">yolo11n-cls-f9</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/y7lutflx' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/y7lutflx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f9, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f9/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f9/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:52<00:00, 39.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:13<00:00, 41.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f9/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.45G      1.145         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:12<00:00,  3.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.684      0.973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 219.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f9/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f9/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f9/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.689      0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 181.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f9/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.68941</td></tr><tr><td>metrics/accuracy_top5</td><td>0.97127</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.859</td></tr><tr><td>train/loss</td><td>1.14524</td></tr><tr><td>val/loss</td><td>0.90203</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f9</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/y7lutflx' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/y7lutflx</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_183001-y7lutflx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa78488ad50>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.830341100692749\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.6894075274467468, 'metrics/accuracy_top5': 0.9712746739387512, 'fitness': 0.830341100692749}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f9/train')\n",
      "speed: {'preprocess': 0.40436827827828536, 'inference': 0.8589269478301245, 'loss': 0.00023343095587670162, 'postprocess': 0.0008040915483264403}\n",
      "task: 'classify'\n",
      "top1: 0.6894075274467468\n",
      "top5: 0.9712746739387512\n",
      "loading the model 'yolo11n-cls-f9' with the weights at 'data/runs/sota/yolo11n-cls-f9/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_183436-x1nby4qe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/x1nby4qe' target=\"_blank\">yolo11n-cls-f9</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/x1nby4qe' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/x1nby4qe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:09<00:00, 59.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:08<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.689      0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f9/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f9</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/x1nby4qe' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/x1nby4qe</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_183436-x1nby4qe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 10 ...\n",
      "Fold 10: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11n-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_183944-302s4fhg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/302s4fhg' target=\"_blank\">yolo11n-cls-f10</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/302s4fhg' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/302s4fhg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11n-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11n-cls-f10, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11n-cls-f10/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 10                  -1  1    339207  ultralytics.nn.modules.head.Classify         [256, 7]                      \n",
      "YOLO11n-cls summary: 86 layers, 1,540,071 parameters, 1,540,071 gradients, 3.3 GFLOPs\n",
      "Transferred 234/236 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11n-cls-f10/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:50<00:00, 39.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:16<00:00, 34.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 39 weight(decay=0.0), 40 weight(decay=0.0005), 40 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11n-cls-f10/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      1.58G      1.137         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:08<00:00,  3.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.697      0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 2,807,024 parameters, 0 gradients, 4.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.76it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 191.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f10/train/weights/last.pt, 3.2MB\n",
      "Optimizer stripped from data/runs/sota/yolo11n-cls-f10/train/weights/best.pt, 3.2MB\n",
      "\n",
      "Validating data/runs/sota/yolo11n-cls-f10/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:03<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.707      0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 186.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 0.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f10/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.70736</td></tr><tr><td>metrics/accuracy_top5</td><td>0.96589</td></tr><tr><td>model/GFLOPs</td><td>3.259</td></tr><tr><td>model/parameters</td><td>1540071</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>0.824</td></tr><tr><td>train/loss</td><td>1.13735</td></tr><tr><td>val/loss</td><td>0.89827</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f10</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/302s4fhg' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/302s4fhg</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_183944-302s4fhg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fa8022c9520>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8366247713565826\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.7073608636856079, 'metrics/accuracy_top5': 0.9658886790275574, 'fitness': 0.8366247713565826}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11n-cls-f10/train')\n",
      "speed: {'preprocess': 0.4651147449603121, 'inference': 0.8244450844463156, 'loss': 0.0002481563445648824, 'postprocess': 0.0006219622853782221}\n",
      "task: 'classify'\n",
      "top1: 0.7073608636856079\n",
      "top5: 0.9658886790275574\n",
      "loading the model 'yolo11n-cls-f10' with the weights at 'data/runs/sota/yolo11n-cls-f10/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250731_184414-1jc1xpmi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1jc1xpmi' target=\"_blank\">yolo11n-cls-f10</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1jc1xpmi' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1jc1xpmi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:11<00:00, 47.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:09<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.725       0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11n-cls summary (fused): 47 layers, 1,534,991 parameters, 0 gradients, 3.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 1.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11n-cls-f10/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n-cls-f10</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1jc1xpmi' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/1jc1xpmi</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250731_184414-1jc1xpmi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/runs/sota/yolo11n-cls-full-balanced/test/metrics.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msota\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SOTAFoldCrossValidation, MultiRunSOTATrainArgs\n\u001b[1;32m      3\u001b[0m cross_validation \u001b[38;5;241m=\u001b[39m SOTAFoldCrossValidation(data_root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n-cls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m     train_run_args\u001b[38;5;241m=\u001b[39mMultiRunSOTATrainArgs(runs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, balanced\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m      6\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtechniques\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     yolo_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n-cls\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcross_validation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/src/sota/model.py:109\u001b[0m, in \u001b[0;36mAbstractFoldCrossValidation.train_folds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_model(model)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_fold()\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_box_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/src/sota/model.py:178\u001b[0m, in \u001b[0;36mSOTAFoldCrossValidation.print_box_plot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_model \u001b[38;5;129;01min\u001b[39;00m fold_models:\n\u001b[1;32m    177\u001b[0m     sota \u001b[38;5;241m=\u001b[39m SOTA(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, fold_model, dataset_name\u001b[38;5;241m=\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_fold\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 178\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mappend(\u001b[43msota\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_test_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics/accuracy_top1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Top 1 accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage(metrics)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    182\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/src/sota/model.py:287\u001b[0m, in \u001b[0;36mSOTA.get_test_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_test_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_project_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetrics.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m load(file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/runs/sota/yolo11n-cls-full-balanced/test/metrics.json'"
     ]
    }
   ],
   "source": [
    "from src.sota.model import SOTAFoldCrossValidation, MultiRunSOTATrainArgs\n",
    "\n",
    "cross_validation = SOTAFoldCrossValidation(data_root=\"data\", \n",
    "    model_name=\"yolo11n-cls\", \n",
    "    train_run_args=MultiRunSOTATrainArgs(runs=1, epochs=1, balanced=False),\n",
    "    dataset_name=\"techniques\",\n",
    "    yolo_model=\"yolo11n-cls\")\n",
    "\n",
    "cross_validation.train_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top 1 accuracy: 0.7085610270500183\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "cross_validation.print_box_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top 1 accuracy: 0.7085610270500183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from src.sota.model import SOTA\n",
    "from numpy import average\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_avg_test_performance(data_root, base_name):\n",
    "    model_root = join(data_root, \"runs\", \"sota\")\n",
    "    fold_models = [model_path for model_path in listdir(model_root) if f\"{base_name}-f\" in model_path]\n",
    "    metrics = []\n",
    "    for fold_model in fold_models:\n",
    "        sota = SOTA(\"data\", fold_model)\n",
    "        metrics.append(sota.get_test_metrics()[\"metrics/accuracy_top1\"])\n",
    "\n",
    "    print(f\"Average Top 1 accuracy: {average(metrics)}\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.boxplot(metrics)\n",
    "    plt.show()\n",
    "\n",
    "calculate_avg_test_performance(\"data\", \"yolo11n-cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "data_root = \"data/img/techniques_kf\"\n",
    "\n",
    "filenames = glob(data_root + \"/all/**/*.*\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "path_to_all = join(\"data\", \"img\", \"techniques_kf\", \"all\")\n",
    "glob(path_to_all + \"/**/*.*\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from shutil import rmtree, copy\n",
    "from random import random\n",
    "from numpy import average\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.sampling.images import build_image_dirs\n",
    "from src.sota.model import SOTA\n",
    "\n",
    "def build_fold(data_root, fold_idx, train_idx, test_idx, filenames):\n",
    "    fold_num = fold_idx + 1\n",
    "    build_image_dirs(join(data_root, \"current_fold\"))\n",
    "    print(f\"Building fold {fold_num} ...\")\n",
    "    train_ratio = 0.9\n",
    "\n",
    "    for filename_idx in train_idx:\n",
    "        src = filenames[filename_idx]\n",
    "        dest = src.replace(\"/all/\", \"/current_fold/train/\")  \\\n",
    "            if random() < train_ratio \\\n",
    "            else src.replace(\"/all/\", \"/current_fold/val/\")\n",
    "        \n",
    "        copy(src, dest)\n",
    "\n",
    "    for filename_idx in test_idx:\n",
    "        src = filenames[filename_idx]\n",
    "        dest = src.replace(\"/all/\", \"/current_fold/test/\")\n",
    "        copy(src, dest)\n",
    "\n",
    "    train_len = len(glob(data_root + \"/current_fold/train/**/*.*\", recursive=True))\n",
    "    val_len = len(glob(data_root + \"/current_fold/val/**/*.*\", recursive=True))\n",
    "    test_len = len(glob(data_root + \"/current_fold/test/**/*.*\", recursive=True))\n",
    "    print(f\"Fold {fold_num}: Train size = {train_len}, Val size = {val_len}, Test size = {test_len}\")\n",
    "    \n",
    "def clear_fold(data_root):\n",
    "    rmtree(join(data_root, \"current_fold\"))\n",
    "\n",
    "def calculate_avg_test_performance(data_root, base_name):\n",
    "    model_root = join(data_root, \"runs\", \"sota\")\n",
    "    fold_models = [model_path for model_path in listdir(model_root) if f\"{base_name}-f\" in model_path]\n",
    "    metrics = []\n",
    "    for fold_model in fold_models:\n",
    "        sota = SOTA(\"data\", fold_model)\n",
    "        metrics.append(sota.get_test_metrics()[\"metrics/accuracy_top1\"])\n",
    "\n",
    "    print(f\"Average Top 1 accuracy: {average(metrics)}\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.boxplot(metrics)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for i, (train, test) in enumerate(kf.split(filenames)):\n",
    "    build_fold(data_root, i, train, test, filenames)\n",
    "\n",
    "    sota = SOTA(\"data\", f\"yolo11m-cls-f{i + 1}\", dataset_name=\"techniques_kf/current_fold\")\n",
    "    sota.execute_train_runs(model=\"yolo11m-cls\", runs=1, epochs=5, balanced=False)\n",
    "\n",
    "    sota.test_model(write_to_wandb=False)\n",
    "\n",
    "    clear_fold(data_root)\n",
    "\n",
    "    if (i == 1):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "sota.test_model(write_to_wandb=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_avg_test_performance(\"data\", \"yolo11m-cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_fold(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sota model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "sota.execute_train_runs(model=\"yolo11m-cls\", runs=3, epochs=10, balanced=False)\n",
    "#sota.train_model(optimizer=\"AdamW\", lr0=0.0005)\n",
    "\n",
    "#metrics = model.val(data=\"data/img/techniques/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-cls\")\n",
    "sota.execute_train_runs(model=\"yolo11n-cls\", runs=5, epochs=10, balanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls-balanced\")\n",
    "sota.execute_train_runs(model=\"yolo11m-cls\", runs=5, epochs=10, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-cls-full-balanced\")\n",
    "sota.execute_train_runs(model=\"yolo11n-cls\", runs=2, epochs=5, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11m-cls\")\n",
    "sota.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11n-cls\")\n",
    "#sota.train_model()\n",
    "sota.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sota model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "metrics = sota.test_model(write_to_wandb=False)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.top1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPE DNN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1\")\n",
    "hpednn.execute_train_runs(runs=5, epochs=10, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1-balanced\")\n",
    "hpednn.execute_train_runs(runs=5, epochs=10, augment=True, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "run_dir = join(\"data\", \"sota\", \"yolo11n-cls-full-balanced\")\n",
    "run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_augmented\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch2_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH2)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch3_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_full_balanced\")\n",
    "hpednn.execute_train_runs(runs=2, epochs=10, augment=True, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_not_norm\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, normalize=False)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_dr_0.3\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, dropout_rate=0.3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir data/runs/hpe_dnn/arch1_balanced/train1/logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import read_data\n",
    "\n",
    "df_path = \"data/df/techniques/train.pkl\"\n",
    "train = read_data(df_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
