{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sampling.images import plot_frame_count_distributions\n",
    "\n",
    "samples_root_dir = \"data/samples\"\n",
    "\n",
    "plot_frame_count_distributions(samples_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "sota.initialize_model()\n",
    "sota.train_model(optimizer=\"AdamW\", lr0=0.0005)\n",
    "\n",
    "\n",
    "#metrics = model.val(data=\"data/img/techniques/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-cls\")\n",
    "sota.initialize_model()\n",
    "sota.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11m-cls\")\n",
    "sota.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11n-cls\")\n",
    "#sota.train_model()\n",
    "sota.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 14:52:37.514146: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751028758.578061   56302 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751028758.871235   56302 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-27 14:52:41.602255: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/mnt/c/Projects/climbing-technique-detector/.venv/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading a fresh model 'arch1_augmented'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_HpeDnn__df_to_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhpe_dnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HpeDnn\n\u001b[1;32m      3\u001b[0m hpednn_aug \u001b[38;5;241m=\u001b[39m HpeDnn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124march1_augmented\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mhpednn_aug\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m hpednn_aug\u001b[38;5;241m.\u001b[39mtrain_model(augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/src/hpe_dnn/model.py:291\u001b[0m, in \u001b[0;36mHpeDnn.initialize_model\u001b[0;34m(self, arch, normalize, dropout_rate)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__load_model(model_path)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__fresh_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/src/hpe_dnn/model.py:354\u001b[0m, in \u001b[0;36mHpeDnn.__fresh_model\u001b[0;34m(self, arch, normalize, dropout_rate)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__fresh_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, arch: DnnArch, normalize, dropout_rate):\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a fresh model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 354\u001b[0m     train_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_data_from_split\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m     debugging \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     model_func \u001b[38;5;241m=\u001b[39m _arch_mapping[arch]\n",
      "File \u001b[0;32m/mnt/c/Projects/climbing-technique-detector/src/hpe_dnn/model.py:361\u001b[0m, in \u001b[0;36mHpeDnn.__get_data_from_split\u001b[0;34m(self, split, augment)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__get_data_from_split\u001b[39m(\u001b[38;5;28mself\u001b[39m, split: \u001b[38;5;28mstr\u001b[39m, augment) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset:\n\u001b[1;32m    360\u001b[0m     df \u001b[38;5;241m=\u001b[39m read_data(join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_dataset_dir(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__df_to_dataset\u001b[49m(df, augment\u001b[38;5;241m=\u001b[39maugment)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_HpeDnn__df_to_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn_aug = HpeDnn(\"data\", \"arch1_augmented\")\n",
    "hpednn_aug.initialize_model()\n",
    "hpednn_aug.train_model(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch2_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH2)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch3_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_not_norm\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, normalize=False)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_dr_0.3\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, dropout_rate=0.3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir data/runs/hpe_dnn/arch1_balanced/train1/logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from cv2 import imread\n",
    "import numpy as np\n",
    "\n",
    "from src.hpe.evaluate import predict_landmarks\n",
    "from src.hpe.model import build_holistic_model\n",
    "from src.hpe_dnn.augmentation import __transform_pipeline\n",
    "\n",
    "image_file_path = \"data/img/techniques/train/CROSS_MIDLINE/(Climbing Analysis) Inside Flag - The Move You Never Do But Maybe Should__1647__9.png\"\n",
    "image2_file_path = \"data/img/techniques/train/CROSS_MIDLINE/Route1Climb2__972__20.png\"\n",
    "\n",
    "for image_path in [image_file_path, image2_file_path]:\n",
    "\n",
    "    image = imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    with build_holistic_model() as model:\n",
    "\n",
    "        result, _ = predict_landmarks(image, model)\n",
    "        (keypoints, vis, labels) = __to_augmenting_array2(result, height, width)\n",
    "\n",
    "        vis_keypoints(image, keypoints)   \n",
    "\n",
    "        transformed = __transform_pipeline(image=image, keypoints=keypoints)\n",
    "        print(transformed['keypoints'])\n",
    "        \n",
    "        vis_keypoints(transformed['image'], transformed['keypoints'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.evaluate import __to_np_array\n",
    "\n",
    "for image_path in [image_file_path, image2_file_path]:\n",
    "\n",
    "    image = imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    with build_holistic_model() as model:\n",
    "\n",
    "        result, _ = predict_landmarks(image, model)\n",
    "        before = __to_np_array(result)\n",
    "        print(f\"Before: {before}\")\n",
    "\n",
    "        (keypoints, vis, labels, mask) = __to_augmenting_array(result, height, width)\n",
    "        \n",
    "        #after = __to_feature_vector(keypoints, vis, labels, mask, heigth, width)\n",
    "        \n",
    "        transformed = __transform_pipeline(image=image, keypoints=keypoints)\n",
    "        after = __to_feature_vector(transformed['keypoints'], vis, labels, mask, height, width)\n",
    "        print(f\"After: {after}\")\n",
    "\n",
    "        print(f\"Success?: {before == after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(before.shape)\n",
    "print(after.shape)\n",
    "print(labels)\n",
    "print([label in _used_hand_landmarks for label in labels])\n",
    "print(type(labels))\n",
    "print(type(labels[-1]))\n",
    "print(len(keypoints))\n",
    "print(len(transformed['keypoints']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import read_data\n",
    "\n",
    "df_path = \"data/df/techniques/train.pkl\"\n",
    "train = read_data(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import imread\n",
    "\n",
    "from src.hpe.model import build_holistic_model\n",
    "from src.hpe_dnn.augmentation import __transform_pipeline, __to_augmenting_array, __to_df_row\n",
    "\n",
    "def augment(series):\n",
    "    img_path = series[\"image_path\"]\n",
    "    image = imread(img_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    with build_holistic_model() as model:\n",
    "\n",
    "        keypoints, vis = __to_augmenting_array(series, height, width)\n",
    "        \n",
    "        print(\"Before: \" + keypoints)\n",
    "        \n",
    "        after = __to_df_row(series, keypoints, vis, height, width)\n",
    "        \n",
    "        print(f\"After: {after}\")\n",
    "\n",
    "\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import imread\n",
    "\n",
    "from src.hpe_dnn.model import read_data\n",
    "from src.hpe_dnn.augmentation import __transform_pipeline, __to_augmenting_array, __to_df_row\n",
    "from src.hpe_dnn.draw import draw_augmented_keypoints\n",
    "\n",
    "df_path = \"data/df/techniques/train.pkl\"\n",
    "train = read_data(df_path)\n",
    "\n",
    "def print_info(input):\n",
    "    img_path = input[\"image_path\"]\n",
    "    image = imread(img_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    xyz, vis = __to_augmenting_array(input, height, width)\n",
    "    \n",
    "    transformed = __transform_pipeline(image=image, keypoints=xyz)\n",
    "\n",
    "    draw_augmented_keypoints(transformed['image'], transformed['keypoints'])\n",
    "\n",
    "    output = __to_df_row(input, transformed['keypoints'], vis, height, width)\n",
    "\n",
    "    for header in input.index:\n",
    "        print(f\"{header}: {input[header]} ===> {output[header]}\")    \n",
    "\n",
    "    return output\n",
    "\n",
    "train.head().apply(print_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
