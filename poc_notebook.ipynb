{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sampling.images import plot_frame_count_distributions\n",
    "\n",
    "samples_root_dir = \"data/samples\"\n",
    "\n",
    "plot_frame_count_distributions(samples_root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sota K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "data_root = \"data/img/techniques_kf\"\n",
    "\n",
    "filenames = glob(data_root + \"/all/**/*.*\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from shutil import rmtree, copy\n",
    "from random import random\n",
    "from numpy import average\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.sampling.images import __build_image_dirs\n",
    "from src.sota.model import SOTA\n",
    "\n",
    "def build_fold(data_root, fold_idx, train_idx, test_idx, filenames):\n",
    "    fold_num = fold_idx + 1\n",
    "    __build_image_dirs(join(data_root, \"current_fold\"))\n",
    "    print(f\"Building fold {fold_num} ...\")\n",
    "    train_ratio = 0.9\n",
    "\n",
    "    for filename_idx in train_idx:\n",
    "        src = filenames[filename_idx]\n",
    "        dest = src.replace(\"/all/\", \"/current_fold/train/\")  \\\n",
    "            if random() < train_ratio \\\n",
    "            else src.replace(\"/all/\", \"/current_fold/val/\")\n",
    "        \n",
    "        copy(src, dest)\n",
    "\n",
    "    for filename_idx in test_idx:\n",
    "        src = filenames[filename_idx]\n",
    "        dest = src.replace(\"/all/\", \"/current_fold/test/\")\n",
    "        copy(src, dest)\n",
    "\n",
    "    train_len = len(glob(data_root + \"/current_fold/train/**/*.*\", recursive=True))\n",
    "    val_len = len(glob(data_root + \"/current_fold/val/**/*.*\", recursive=True))\n",
    "    test_len = len(glob(data_root + \"/current_fold/test/**/*.*\", recursive=True))\n",
    "    print(f\"Fold {fold_num}: Train size = {train_len}, Val size = {val_len}, Test size = {test_len}\")\n",
    "    \n",
    "def clear_fold(data_root):\n",
    "    rmtree(join(data_root, \"current_fold\"))\n",
    "\n",
    "def calculate_avg_test_performance(data_root, base_name):\n",
    "    model_root = join(data_root, \"runs\", \"sota\")\n",
    "    fold_models = [model_path for model_path in listdir(model_root) if f\"{base_name}-f\" in model_path]\n",
    "    metrics = []\n",
    "    for fold_model in fold_models:\n",
    "        sota = SOTA(\"data\", fold_model)\n",
    "        metrics.append(sota.get_test_metrics()[\"metrics/accuracy_top1\"])\n",
    "\n",
    "    print(f\"Average Top 1 accuracy: {average(metrics)}\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.boxplot(metrics)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for i, (train, test) in enumerate(kf.split(filenames)):\n",
    "    build_fold(data_root, i, train, test, filenames)\n",
    "\n",
    "    sota = SOTA(\"data\", f\"yolo11m-cls-f{i + 1}\", dataset_name=\"techniques_kf/current_fold\")\n",
    "    sota.execute_train_runs(model=\"yolo11m-cls\", runs=1, epochs=5, balanced=False)\n",
    "\n",
    "    sota.test_model(write_to_wandb=False)\n",
    "\n",
    "    clear_fold(data_root)\n",
    "\n",
    "    if (i == 1):\n",
    "        break\n",
    "\n",
    "\n",
    "calculate_avg_test_performance(\"data\", \"yolo11m-cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "sota.execute_train_runs(model=\"yolo11m-cls\", runs=1, epochs=1, balanced=False)\n",
    "\n",
    "#sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "sota.test_model(write_to_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import rename\n",
    "\n",
    "rename(\"data/img/techniques_kf/current_fold/val\", \"data/img/techniques_kf/current_fold/test\")\n",
    "rename(\"data/img/techniques_kf/current_fold/val_temp\", \"data/img/techniques_kf/current_fold/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_fold(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sota model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "sota.execute_train_runs(model=\"yolo11m-cls\", runs=3, epochs=10, balanced=False)\n",
    "#sota.train_model(optimizer=\"AdamW\", lr0=0.0005)\n",
    "\n",
    "#metrics = model.val(data=\"data/img/techniques/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-cls\")\n",
    "sota.execute_train_runs(model=\"yolo11n-cls\", runs=5, epochs=10, balanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls-balanced\")\n",
    "sota.execute_train_runs(model=\"yolo11m-cls\", runs=5, epochs=10, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-cls-full-balanced\")\n",
    "sota.execute_train_runs(model=\"yolo11n-cls\", runs=2, epochs=5, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11m-cls\")\n",
    "sota.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11n-cls\")\n",
    "#sota.train_model()\n",
    "sota.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sota model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "metrics = sota.test_model(write_to_wandb=False)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.top1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPE DNN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1\")\n",
    "hpednn.execute_train_runs(runs=5, epochs=10, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1-balanced\")\n",
    "hpednn.execute_train_runs(runs=5, epochs=10, augment=True, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "run_dir = join(\"data\", \"sota\", \"yolo11n-cls-full-balanced\")\n",
    "run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_augmented\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch2_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH2)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch3_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_full_balanced\")\n",
    "hpednn.execute_train_runs(runs=2, epochs=10, augment=True, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_not_norm\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, normalize=False)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_dr_0.3\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, dropout_rate=0.3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir data/runs/hpe_dnn/arch1_balanced/train1/logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import read_data\n",
    "\n",
    "df_path = \"data/df/techniques/train.pkl\"\n",
    "train = read_data(df_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
