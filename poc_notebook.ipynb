{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sampling.images import plot_frame_count_distributions\n",
    "\n",
    "samples_root_dir = \"data/samples\"\n",
    "\n",
    "plot_frame_count_distributions(samples_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "sota.initialize_model()\n",
    "sota.train_model(optimizer=\"AdamW\", lr0=0.0005)\n",
    "\n",
    "#metrics = model.val(data=\"data/img/techniques/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-cls\")\n",
    "sota.initialize_model()\n",
    "sota.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11m-cls\")\n",
    "sota.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11n-cls\")\n",
    "#sota.train_model()\n",
    "sota.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn_aug = HpeDnn(\"data\", \"arch1_augmented\")\n",
    "hpednn_aug.initialize_model()\n",
    "hpednn_aug.train_model(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_augmented\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch2_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH2)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch3_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_not_norm\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, normalize=False)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_dr_0.3\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, dropout_rate=0.3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir data/runs/hpe_dnn/arch1_balanced/train1/logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe.evaluate import __to_np_array\n",
    "\n",
    "for image_path in [image_file_path, image2_file_path]:\n",
    "\n",
    "    image = imread(image_path)\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    with build_holistic_model() as model:\n",
    "\n",
    "        result, _ = predict_landmarks(image, model)\n",
    "        before = __to_np_array(result)\n",
    "        print(f\"Before: {before}\")\n",
    "\n",
    "        (keypoints, vis, labels, mask) = __to_augmenting_array(result, height, width)\n",
    "        \n",
    "        #after = __to_feature_vector(keypoints, vis, labels, mask, heigth, width)\n",
    "        \n",
    "        transformed = __transform_pipeline(image=image, keypoints=keypoints)\n",
    "        after = __to_feature_vector(transformed['keypoints'], vis, labels, mask, height, width)\n",
    "        print(f\"After: {after}\")\n",
    "\n",
    "        print(f\"Success?: {before == after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(before.shape)\n",
    "print(after.shape)\n",
    "print(labels)\n",
    "print([label in _used_hand_landmarks for label in labels])\n",
    "print(type(labels))\n",
    "print(type(labels[-1]))\n",
    "print(len(keypoints))\n",
    "print(len(transformed['keypoints']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import read_data\n",
    "\n",
    "df_path = \"data/df/techniques/train.pkl\"\n",
    "train = read_data(df_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
