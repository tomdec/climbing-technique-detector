{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sampling.images import plot_frame_count_distributions\n",
    "\n",
    "samples_root_dir = \"data/samples\"\n",
    "\n",
    "plot_frame_count_distributions(samples_root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sota K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 1 ...\n",
      "Fold 1: Train size = 4395, Val size = 546, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11m-cls'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtom-decoutere\u001b[0m (\u001b[33mtom-decoutere-open-universiteit\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for wandb.init()..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250801_090952-ngtyhcir</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/ngtyhcir' target=\"_blank\">yolo11m-cls-fold1</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/ngtyhcir' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/ngtyhcir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11m-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11m-cls-fold1, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11m-cls-fold1/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4395 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 546 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754032214.091189   42430 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754032214.453476   42430 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 10                  -1  1    666887  ultralytics.nn.modules.head.Classify         [512, 7]                      \n",
      "YOLO11m-cls summary: 106 layers, 10,362,183 parameters, 10,362,183 gradients, 39.6 GFLOPs\n",
      "Transferred 294/296 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11m-cls-fold1/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4395 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4395/4395 [01:15<00:00, 57.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 546 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 546/546 [00:10<00:00, 51.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 49 weight(decay=0.0), 50 weight(decay=0.0005), 50 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11m-cls-fold1/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      5.98G      1.084         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 275/275 [01:13<00:00,  3.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:05<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.705      0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 11,622,632 parameters, 0 gradients, 40.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 193.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.027 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11m-cls-fold1/train/weights/last.pt, 20.9MB\n",
      "Optimizer stripped from data/runs/sota/yolo11m-cls-fold1/train/weights/best.pt, 20.9MB\n",
      "\n",
      "Validating data/runs/sota/yolo11m-cls-fold1/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 10,350,599 parameters, 0 gradients, 39.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4395 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 546 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.712      0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 172.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 2.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11m-cls-fold1/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.71245</td></tr><tr><td>metrics/accuracy_top5</td><td>0.98901</td></tr><tr><td>model/GFLOPs</td><td>39.61</td></tr><tr><td>model/parameters</td><td>10362183</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>2.337</td></tr><tr><td>train/loss</td><td>1.08357</td></tr><tr><td>val/loss</td><td>0.80553</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11m-cls-fold1</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/ngtyhcir' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/ngtyhcir</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250801_090952-ngtyhcir/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f20b545cfe0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8507325947284698\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.7124541997909546, 'metrics/accuracy_top5': 0.9890109896659851, 'fitness': 0.8507325947284698}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11m-cls-fold1/train')\n",
      "speed: {'preprocess': 0.44039905127973705, 'inference': 2.336621966932375, 'loss': 0.0006446704198521027, 'postprocess': 0.0032885622164070772}\n",
      "task: 'classify'\n",
      "top1: 0.7124541997909546\n",
      "top5: 0.9890109896659851\n",
      "loading the model 'yolo11m-cls-fold1' with the weights at 'data/runs/sota/yolo11m-cls-fold1/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250801_091618-0wxfnp3f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/0wxfnp3f' target=\"_blank\">yolo11m-cls-fold1</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/0wxfnp3f' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/0wxfnp3f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 10,350,599 parameters, 0 gradients, 39.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4395 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:13<00:00, 40.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:09<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.729      0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 10,350,599 parameters, 0 gradients, 39.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.6ms preprocess, 5.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11m-cls-fold1/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11m-cls-fold1</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/0wxfnp3f' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/0wxfnp3f</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250801_091618-0wxfnp3f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building fold 2 ...\n",
      "Fold 2: Train size = 4384, Val size = 557, Test size = 549\n",
      "starting run #0\n",
      "loading a fresh model 'yolo11m-cls'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250801_092126-e4dgkx53</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/e4dgkx53' target=\"_blank\">yolo11m-cls-fold2</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/e4dgkx53' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/e4dgkx53</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.171 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11m-cls.pt, data=data/img/techniques_kf/current_fold, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=data/runs/sota/yolo11m-cls-fold2, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=data/runs/sota/yolo11m-cls-fold2/train\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 10                  -1  1    666887  ultralytics.nn.modules.head.Classify         [512, 7]                      \n",
      "YOLO11m-cls summary: 106 layers, 10,362,183 parameters, 10,362,183 gradients, 39.6 GFLOPs\n",
      "Transferred 294/296 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir data/runs/sota/yolo11m-cls-fold2/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... 4384 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4384/4384 [01:31<00:00, 48.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 557 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 557/557 [00:11<00:00, 46.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 49 weight(decay=0.0), 50 weight(decay=0.0005), 50 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mdata/runs/sota/yolo11m-cls-fold2/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      6.28G      1.085         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [01:10<00:00,  3.86it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.677      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 11,622,632 parameters, 0 gradients, 40.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 149.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epochs completed in 0.025 hours.\n",
      "Optimizer stripped from data/runs/sota/yolo11m-cls-fold2/train/weights/last.pt, 20.9MB\n",
      "Optimizer stripped from data/runs/sota/yolo11m-cls-fold2/train/weights/best.pt, 20.9MB\n",
      "\n",
      "Validating data/runs/sota/yolo11m-cls-fold2/train/weights/best.pt...\n",
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 10,350,599 parameters, 0 gradients, 39.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 557 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/test... found 549 images in 7 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:04<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.675      0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 138.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 2.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11m-cls-fold2/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>‚ñÅ</td></tr><tr><td>lr/pg1</td><td>‚ñÅ</td></tr><tr><td>lr/pg2</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top1</td><td>‚ñÅ</td></tr><tr><td>metrics/accuracy_top5</td><td>‚ñÅ</td></tr><tr><td>model/GFLOPs</td><td>‚ñÅ</td></tr><tr><td>model/parameters</td><td>‚ñÅ</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñÅ</td></tr><tr><td>val/loss</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.0003</td></tr><tr><td>lr/pg1</td><td>0.0003</td></tr><tr><td>lr/pg2</td><td>0.0003</td></tr><tr><td>metrics/accuracy_top1</td><td>0.67504</td></tr><tr><td>metrics/accuracy_top5</td><td>0.96948</td></tr><tr><td>model/GFLOPs</td><td>39.61</td></tr><tr><td>model/parameters</td><td>10362183</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>2.379</td></tr><tr><td>train/loss</td><td>1.08484</td></tr><tr><td>val/loss</td><td>1.02802</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11m-cls-fold2</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/e4dgkx53' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/e4dgkx53</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 22 media file(s), 8 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250801_092126-e4dgkx53/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.utils.metrics.ClassifyMetrics object with attributes:\n",
      "\n",
      "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f20b7bcbfb0>\n",
      "curves: []\n",
      "curves_results: []\n",
      "fitness: 0.8222621381282806\n",
      "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
      "results_dict: {'metrics/accuracy_top1': 0.6750448942184448, 'metrics/accuracy_top5': 0.9694793820381165, 'fitness': 0.8222621381282806}\n",
      "save_dir: PosixPath('data/runs/sota/yolo11m-cls-fold2/train')\n",
      "speed: {'preprocess': 0.4817438814529892, 'inference': 2.3793721687248484, 'loss': 0.0028657737707207566, 'postprocess': 0.009089705663443921}\n",
      "task: 'classify'\n",
      "top1: 0.6750448942184448\n",
      "top5: 0.9694793820381165\n",
      "loading the model 'yolo11m-cls-fold2' with the weights at 'data/runs/sota/yolo11m-cls-fold2/train/weights/best.pt'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>data/wandb/run-20250801_092645-fxnmwopp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/fxnmwopp' target=\"_blank\">yolo11m-cls-fold2</a></strong> to <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/fxnmwopp' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/fxnmwopp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 10,350,599 parameters, 0 gradients, 39.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/train... found 4384 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... found 549 images in 7 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val... 549 images, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 549/549 [00:12<00:00, 44.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Projects/climbing-technique-detector/data/img/techniques_kf/current_fold/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:09<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.678      0.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78 üöÄ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (NVIDIA TITAN RTX, 24576MiB)\n",
      "YOLO11m-cls summary (fused): 57 layers, 10,350,599 parameters, 0 gradients, 39.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Visualizations for batch-1/1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.5ms preprocess, 4.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mdata/runs/sota/yolo11m-cls-fold2/test\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11m-cls-fold2</strong> at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/fxnmwopp' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique/runs/fxnmwopp</a><br> View project at: <a href='https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique' target=\"_blank\">https://wandb.ai/tom-decoutere-open-universiteit/detect-climbing-technique</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>data/wandb/run-20250801_092645-fxnmwopp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top 1 accuracy: 0.7030965387821198\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from src.sota.model import SOTAFoldCrossValidation, MultiRunSOTATrainArgs, SOTATrainArgs\n",
    "\n",
    "cross_validation = SOTAFoldCrossValidation(data_root=\"data\", \n",
    "    model_name=\"yolo11m-cls\", \n",
    "    dataset_name=\"techniques\",\n",
    "    train_run_args=MultiRunSOTATrainArgs(model=\"yolo11m-cls\", runs=1,\n",
    "        train_args=SOTATrainArgs(epochs=1, balanced=False)))\n",
    "\n",
    "cross_validation.train_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top 1 accuracy: 0.7085610270500183\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cross_validation = SOTAFoldCrossValidation(data_root=\"data\", \n",
    "    model_name=\"yolo11n-cls\", \n",
    "    dataset_name=\"techniques\",\n",
    "    train_run_args=MultiRunSOTATrainArgs(model=\"yolo11n-cls\", runs=1, \n",
    "        train_args=SOTATrainArgs(epochs=1, balanced=False)))\n",
    "\n",
    "cross_validation.print_box_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sota model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "sota.execute_train_runs(model=\"yolo11m-cls\", runs=3, epochs=10, balanced=False)\n",
    "#sota.train_model(optimizer=\"AdamW\", lr0=0.0005)\n",
    "\n",
    "#metrics = model.val(data=\"data/img/techniques/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-cls\")\n",
    "sota.execute_train_runs(model=\"yolo11n-cls\", runs=5, epochs=10, balanced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls-balanced\")\n",
    "sota.execute_train_runs(model=\"yolo11m-cls\", runs=5, epochs=10, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-cls-full-balanced\")\n",
    "sota.execute_train_runs(model=\"yolo11n-cls\", runs=2, epochs=5, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11m-cls\")\n",
    "sota.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11n-balance-50-155\", dataset_name=\"techniques_balanced\")\n",
    "sota.initialize_model(\"yolo11n-cls\")\n",
    "#sota.train_model()\n",
    "sota.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sota model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sota.model import SOTA\n",
    "\n",
    "sota = SOTA(\"data\", \"yolo11m-cls\")\n",
    "metrics = sota.test_model(write_to_wandb=False)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.top1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPE DNN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1\")\n",
    "hpednn.execute_train_runs(runs=5, epochs=10, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1-balanced\")\n",
    "hpednn.execute_train_runs(runs=5, epochs=10, augment=True, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "run_dir = join(\"data\", \"sota\", \"yolo11n-cls-full-balanced\")\n",
    "run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_augmented\", \"techniques_balanced\")\n",
    "hpednn.initialize_model()\n",
    "hpednn.train_model(augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch2_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH2)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch3_balanced\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_full_balanced\")\n",
    "hpednn.execute_train_runs(runs=2, epochs=10, augment=True, balanced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_not_norm\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, normalize=False)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import HpeDnn, DnnArch\n",
    "\n",
    "hpednn = HpeDnn(\"data\", \"arch1_balanced_dr_0.3\", \"techniques_balanced\")\n",
    "hpednn.initialize_model(DnnArch.ARCH1, dropout_rate=0.3)\n",
    "hpednn.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir data/runs/hpe_dnn/arch1_balanced/train1/logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hpe_dnn.model import read_data\n",
    "\n",
    "df_path = \"data/df/techniques/train.pkl\"\n",
    "train = read_data(df_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
